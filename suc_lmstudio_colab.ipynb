{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LrNXn8dYDQmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKVqt7eGDQbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fRlCi2LyDQPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s0x7EM3RDQL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XN4s0lZQDQIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "termenal\n",
        "\n",
        "\n",
        "\n",
        "content# xvfb-run --auto-servernum ./LM-Studio.AppImage --no-sandbox & && lms server start\n",
        "-bash: syntax error near unexpected token `&&'"
      ],
      "metadata": {
        "id": "dJIsjVG5DSeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "فى خلية\n",
        "\n",
        "%cd /root/lmstudio/bin && lms server start"
      ],
      "metadata": {
        "id": "aeh16KBUDgWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "pip install lmstudio\n",
        "\n",
        "\n",
        "\n",
        "!lms get qwen/qwen3-4b-2507\n",
        "\n",
        "\n",
        "import lmstudio as lms\n",
        "\n",
        "# Connect to the LM Studio server\n",
        "# Assuming the server is running on the default port 1234\n",
        "# If you configured a different port, update this line\n",
        "model = lms.llm(\"qwen/qwen3-4b-2507\")\n",
        "\n",
        "# Test the model\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The question \"What is the meaning of life?\" is one of the most profound and enduring questions in human history. There is no single, universally accepted answer—because meaning is deeply personal and shaped by culture, religion, philosophy, science, and individual experience.\n",
        "\n",
        "Here are several perspectives on the meaning of life:\n",
        "\n",
        "1. **Philosophical Perspectives**  \n",
        "   - **Existentialism** (e.g., Sartre, Camus): Life has no inherent meaning; it is up to each individual to create their own purpose through choices and actions.  \n",
        "   - **Absurdism** (e.g., Camus): The conflict between the human search for meaning and the universe's apparent silence or randomness is absurd—but we can still find value through living authentically despite that absurdity.  \n",
        "   - **Humanism**: Meaning comes from human values—love, creativity, knowledge, and contributing to society.\n",
        "\n",
        "2. **Religious and Spiritual Views**  \n",
        "   - **Christianity, Islam, Judaism**: Life has meaning because it is a gift from a divine being, and the purpose is to live according to God’s will, love others, and prepare for an afterlife.  \n",
        "   - **Buddhism**: The purpose of life is to attain enlightenment and end suffering through wisdom, compassion, and ethical living.  \n",
        "   - **Hinduism**: Life is part of a cycle (samsara), and the ultimate goal is to achieve moksha (liberation) through dharma, karma, and devotion.  \n",
        "\n",
        "3. **Scientific Perspective**  \n",
        "   - From a biological standpoint, life's purpose may be to survive, reproduce, and pass on genes.  \n",
        "   - From a cosmic view, life may be a natural byproduct of the universe's complexity and evolution—meaning is not something \"out there\" but something we construct through experience.\n",
        "\n",
        "4. **Personal Meaning**  \n",
        "   Many people find meaning in relationships, achievements, service to others, creativity, or personal growth. As Viktor Frankl (a Holocaust survivor and psychiatrist) wrote in *Man’s Search for Meaning*, even in suffering, people find purpose through what they value and what they do—such as love, duty, or responsibility.\n",
        "\n",
        "💡 In short:  \n",
        "**The meaning of life is not something discovered in a single moment or a textbook answer. It is something you build through your experiences, relationships, choices, and values.**\n",
        "\n",
        "So, while we may not know the \"one true answer,\" the journey of seeking meaning—living with intention and connection—is itself a powerful and meaningful part of being human.\n",
        "\n",
        "Would you like to explore a particular perspective (e.g., philosophy, religion, science) in more depth?"
      ],
      "metadata": {
        "id": "3Bae0da4ER60"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ag5HmtrxDSKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7K4XlhOVDSHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N3Q5b0AWDSEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OEKsjWTxDSAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NK712S8SDR88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxMLKQ5Mvhpq",
        "outputId": "4f9ddc3f-0cc8-41e1-c4a7-8a49f3673e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lmstudio\n",
            "  Downloading lmstudio-1.5.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.12/dist-packages (from lmstudio) (0.28.1)\n",
            "Collecting httpx-ws>=0.7.0 (from lmstudio)\n",
            "  Downloading httpx_ws-0.8.0-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting msgspec>=0.18.6 (from lmstudio)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from lmstudio) (4.15.0)\n",
            "Requirement already satisfied: anyio>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from lmstudio) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=4.8.0->lmstudio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=4.8.0->lmstudio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->lmstudio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->lmstudio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.2->lmstudio) (0.16.0)\n",
            "Collecting wsproto (from httpx-ws>=0.7.0->lmstudio)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Downloading lmstudio-1.5.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_ws-0.8.0-py3-none-any.whl (14 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, msgspec, httpx-ws, lmstudio\n",
            "Successfully installed httpx-ws-0.8.0 lmstudio-1.5.0 msgspec-0.19.0 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install lmstudio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpQN7mSqvwgP",
        "outputId": "18ec93ae-40f4-4321-9c78-15d7d4185096"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: lms: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lms get qwen/qwen3-4b-2507"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjENX3gwwDLG",
        "outputId": "f6b25938-383c-492c-e247-533225195e72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: lms: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lmstudio as lms\n",
        "\n",
        "model = lms.llm(\"qwen/qwen3-4b-2507\")\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "LBCR0dOWv2HH",
        "outputId": "073ca899-a8df-43b4-d2a2-fbd0f7113df6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LMStudioClientError",
          "evalue": "LM Studio is not reachable at any default port. Is LM Studio running?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLMStudioClientError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3478192561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlmstudio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"qwen/qwen3-4b-2507\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrespond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is the meaning of life?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLMStudioClientError\u001b[0m: LM Studio is not reachable at any default port. Is LM Studio running?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lmstudio as lms\n"
      ],
      "metadata": {
        "id": "lZpl5xD5v684"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y fuse libfuse2 xvfb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgsoRzM0wOoH",
        "outputId": "61c2cfde-07da-471e-81eb-dfdb5ca94d8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/129 kB 11%] [Connect\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [1 InRelease 66.3 kB/129 kB 51%] [2 InRelease 0 B/3,63\r0% [Waiting for headers] [1 InRelease 95.3 kB/129 kB 74%] [Connected to r2u.sta\r                                                                               \rGet:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Waiting for headers] [1 InRelease 104 kB/129 kB 81%] [Waiting for headers] \r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 104 kB/129 kB 81%] [Waiting for headers] \r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://cli.github.com/packages stable/main amd64 Packages [346 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,085 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,468 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,851 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,812 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,288 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,373 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,050 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,798 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Fetched 36.7 MB in 4s (10.0 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fuse is already the newest version (2.9.9-5ubuntu3).\n",
            "libfuse2 is already the newest version (2.9.9-5ubuntu3).\n",
            "libfuse2 set to manually installed.\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل ملف AppImage\n",
        "!wget https://installers.lmstudio.ai/linux/x64/LM-Studio-0.2.22-x86_64.AppImage -O LM-Studio.AppImage\n",
        "\n",
        "# إعطاء صلاحيات التنفيذ للملف\n",
        "!chmod +x LM-Studio.AppImage```\n",
        "\n",
        "### الخطوة 3: التشغيل الأولي لـ LM Studio (خطوة حيوية)\n",
        "\n",
        "هذه هي الخطوة الأهم. يجب تشغيل تطبيق LM Studio مرة واحدة على الأقل لكي يقوم بإنشاء ملفات الإعدادات اللازمة لواجهة سطر الأوامر `lms`. سنستخدم `xvfb-run` لتشغيله في الخلفية دون الحاجة لواجهة رسومية.\n",
        "\n",
        "**ملاحظة:** قد تستغرق هذه الخلية دقيقة أو دقيقتين لتكتمل. لن ترى أي مخرجات مرئية، ولكنها تقوم بالتهيئة في الخلفية.\n",
        "\n",
        "```bash\n",
        "# تشغيل التطبيق في بيئة افتراضية لإنشاء ملفات الإعدادات\n",
        "!xvfb-run --auto-servernum ./LM-Studio.AppImage &\n",
        "# الانتظار لمدة 60 ثانية لإعطاء التطبيق وقتاً كافياً للتهيئة\n",
        "!sleep 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "tb6FqhCZw4iv",
        "outputId": "965a63ce-aedc-4929-95c8-aa61e08c337f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '،' (U+060C) (ipython-input-1278855195.py, line 11)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1278855195.py\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    **ملاحظة:** قد تستغرق هذه الخلية دقيقة أو دقيقتين لتكتمل. لن ترى أي مخرجات مرئية، ولكنها تقوم بالتهيئة في الخلفية.\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '،' (U+060C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل ملف AppImage\n",
        "!wget https://installers.lmstudio.ai/linux/x64/LM-Studio-0.2.22-x86_64.AppImage -O LM-Studio.AppImage\n",
        "\n",
        "# إعطاء صلاحيات التنفيذ للملف\n",
        "!chmod +x LM-Studio.AppImage```"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWvDs4Bhw7Un",
        "outputId": "77b109fa-ceb8-4408-936b-d4bfa60c812e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 02:33:54--  https://installers.lmstudio.ai/linux/x64/LM-Studio-0.2.22-x86_64.AppImage\n",
            "Resolving installers.lmstudio.ai (installers.lmstudio.ai)... 104.26.6.153, 104.26.7.153, 172.67.69.92, ...\n",
            "Connecting to installers.lmstudio.ai (installers.lmstudio.ai)|104.26.6.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-10-22 02:33:54 ERROR 404: Not Found.\n",
            "\n",
            "/bin/bash: -c: line 1: unexpected EOF while looking for matching ``'\n",
            "/bin/bash: -c: line 2: syntax error: unexpected end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!xvfb-run --auto-servernum ./LM-Studio.AppImage &\n",
        "# الانتظار لمدة 60 ثانية لإعطاء التطبيق وقتاً كافياً للتهيئة\n",
        "!sleep 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x3Qs3ZsxAue",
        "outputId": "fe2c4784-83fc-4674-a2d1-af95952f6e5c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xvfb-run: 184: ./LM-Studio.AppImage: Permission denied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تشغيل أمر الإعداد المدمج مع التطبيق\n",
        "!~/.lmstudio/bin/lms bootstrap\n",
        "\n",
        "# إضافة المسار إلى متغيرات البيئة الحالية لتتمكن من استخدام الأمر مباشرة\n",
        "import os\n",
        "os.environ['PATH'] += \":/root/.lmstudio/bin\"\n",
        "\n",
        "# التحقق من أن الأمر يعمل بشكل صحيح\n",
        "!lms status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iENkUJyTxDBW",
        "outputId": "d4efd06d-c8f7-4e5a-c63e-6ec518f87f5d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /root/.lmstudio/bin/lms: No such file or directory\n",
            "/bin/bash: line 1: lms: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y xvfb```\n",
        "\n",
        "### الخطوة 2: تثبيت أحدث إصدار من LM Studio (الطريقة الجديدة)\n",
        "\n",
        "هنا التغيير الرئيسي. بدلاً من محاولة تخمين رابط التحميل، سنقوم بتشغيل البرنامج النصي الرسمي للتثبيت. سيقوم هذا الأمر بإضافة مستودع LM Studio وتثبيت أحدث نسخة من البرنامج.\n",
        "\n",
        "```bash\n",
        "# تحميل وتشغيل البرنامج النصي الرسمي للتثبيت\n",
        "!curl -sSL https://raw.githubusercontent.com/lmstudio-ai/configs/main/apt/install.sh | sudo bash\n",
        "\n",
        "# تثبيت التطبيق باستخدام مدير الحزم apt\n",
        "!sudo apt install lmstudio -y"
      ],
      "metadata": {
        "id": "zeu2FHjJxl31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y xvfb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRbntcpLxn5F",
        "outputId": "73db1be8-8fff-4f19-db7b-cc7a51bd2e51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [W\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [W\r                                                                               \rHit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sSL https://raw.githubusercontent.com/lmstudio-ai/configs/main/apt/install.sh | sudo bash\n",
        "\n",
        "# تثبيت التطبيق باستخدام مدير الحزم apt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxhddNMoxoLf",
        "outputId": "8198a24f-b9b1-4d69-fb67-47d8acd9c8b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: line 1: 404:: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تشغيل التطبيق في بيئة افتراضية لإنشاء ملفات الإعدادات\n",
        "!xvfb-run --auto-servernum lmstudio &\n",
        "# الانتظار لمدة 60 ثانية لإعطاء التطبيق وقتاً كافياً للتهيئة\n",
        "!sleep 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLnMS18rxrEG",
        "outputId": "06585fa1-6c77-4918-eff4-e47841b29133"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xvfb-run: 184: lmstudio: not found\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!run /content/LM-Studio.AppImage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au0VxChWxvVO",
        "outputId": "4cee55f9-37e7-411e-97a1-cdfaa4309cc3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: run: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sSL https://raw.githubusercontent.com/lmstudio-ai/configs/main/apt/install.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JARS2sSXx_9G",
        "outputId": "0e1022f6-ec57-402f-d7a9-170b4b9abdf0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تنزيل سكريبت التثبيت الرسمي إلى ملف محلي اسمه install.sh\n",
        "!wget https://raw.githubusercontent.com/lmstudio-ai/configs/main/apt/install.sh -O install.sh\n",
        "\n",
        "# إعطاء صلاحيات التنفيذ للملف الذي تم تنزيله\n",
        "!chmod +x install.sh\n",
        "\n",
        "# تشغيل السكريبت المحلي باستخدام صلاحيات sudo\n",
        "!sudo ./install.sh\n",
        "\n",
        "# الآن، بعد أن أضاف السكريبت المستودع، نقوم بتثبيت التطبيق\n",
        "!sudo apt install lmstudio -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOzBM1voyTeX",
        "outputId": "f8e6f561-280b-4361-f62b-49fc967faf48"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 02:40:46--  https://raw.githubusercontent.com/lmstudio-ai/configs/main/apt/install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-10-22 02:40:46 ERROR 404: Not Found.\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package lmstudio\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y fuse libfuse2 xvfb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q87KJ1r0ylMe",
        "outputId": "9ae0254f-aa19-48dd-e0f4-7b2684ba92ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connected to cloud.r-pr\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (13.225.47.60)] [Con\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,798 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Fetched 5,520 kB in 3s (2,022 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fuse is already the newest version (2.9.9-5ubuntu3).\n",
            "libfuse2 is already the newest version (2.9.9-5ubuntu3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://releases.lmstudio.ai/linux/0.2.25/LM-Studio-0.2.25-x86_64.AppImage\" -O LM-Studio.AppImage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hayBvMzyw0O",
        "outputId": "7ad11a10-ef95-434a-bc85-aff63a123939"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 02:41:51--  https://releases.lmstudio.ai/linux/0.2.25/LM-Studio-0.2.25-x86_64.AppImage\n",
            "Resolving releases.lmstudio.ai (releases.lmstudio.ai)... 172.67.69.92, 104.26.7.153, 104.26.6.153, ...\n",
            "Connecting to releases.lmstudio.ai (releases.lmstudio.ai)|172.67.69.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-10-22 02:41:51 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://lmstudio.ai/download/latest/linux/x64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldbHYSZSy1F-",
        "outputId": "ee23beea-f32d-4a7e-b349-43a88e1d7c49"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 02:43:26--  https://lmstudio.ai/download/latest/linux/x64\n",
            "Resolving lmstudio.ai (lmstudio.ai)... 104.26.6.153, 172.67.69.92, 104.26.7.153, ...\n",
            "Connecting to lmstudio.ai (lmstudio.ai)|104.26.6.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://installers.lmstudio.ai/linux/x64/0.3.30-2/LM-Studio-0.3.30-2-x64.AppImage [following]\n",
            "--2025-10-22 02:43:27--  https://installers.lmstudio.ai/linux/x64/0.3.30-2/LM-Studio-0.3.30-2-x64.AppImage\n",
            "Resolving installers.lmstudio.ai (installers.lmstudio.ai)... 104.26.7.153, 104.26.6.153, 172.67.69.92, ...\n",
            "Connecting to installers.lmstudio.ai (installers.lmstudio.ai)|104.26.7.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1009916098 (963M) [application/octet-stream]\n",
            "Saving to: ‘x64’\n",
            "\n",
            "x64                 100%[===================>] 963.13M  42.6MB/s    in 27s     \n",
            "\n",
            "2025-10-22 02:43:54 (36.1 MB/s) - ‘x64’ saved [1009916098/1009916098]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل أحدث إصدار وتسميته LM-Studio.AppImage مباشرة\n",
        "!wget \"https://lmstudio.ai/download/latest/linux/x64\" -O LM-Studio.AppImage\n",
        "\n",
        "# إعطاء صلاحيات التنفيذ للملف الذي تم تحميله\n",
        "!chmod +x LM-Studio.AppImage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihj5VGOlzMau",
        "outputId": "21e193d0-8579-49d1-9e1b-1f6d1fb74c7c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 02:45:56--  https://lmstudio.ai/download/latest/linux/x64\n",
            "Resolving lmstudio.ai (lmstudio.ai)... 172.67.69.92, 104.26.7.153, 104.26.6.153, ...\n",
            "Connecting to lmstudio.ai (lmstudio.ai)|172.67.69.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://installers.lmstudio.ai/linux/x64/0.3.30-2/LM-Studio-0.3.30-2-x64.AppImage [following]\n",
            "--2025-10-22 02:45:56--  https://installers.lmstudio.ai/linux/x64/0.3.30-2/LM-Studio-0.3.30-2-x64.AppImage\n",
            "Resolving installers.lmstudio.ai (installers.lmstudio.ai)... 104.26.6.153, 104.26.7.153, 172.67.69.92, ...\n",
            "Connecting to installers.lmstudio.ai (installers.lmstudio.ai)|104.26.6.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1009916098 (963M) [application/octet-stream]\n",
            "Saving to: ‘LM-Studio.AppImage’\n",
            "\n",
            "LM-Studio.AppImage  100%[===================>] 963.13M  46.0MB/s    in 22s     \n",
            "\n",
            "2025-10-22 02:46:19 (43.2 MB/s) - ‘LM-Studio.AppImage’ saved [1009916098/1009916098]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تشغيل التطبيق في بيئة افتراضية لإنشاء ملفات الإعدادات\n",
        "!xvfb-run --auto-servernum ./LM-Studio.AppImage &\n",
        "# الانتظار لمدة 60 ثانية لإعطاء التطبيق وقتاً كافياً للتهيئة\n",
        "!sleep 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpCCEQQtz0__",
        "outputId": "5779f73a-c105-4e65-8efc-3cbe1974011a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1022/024623.121587:FATAL:electron/shell/app/electron_main_delegate.cc:290] Running as root without --no-sandbox is not supported. See https://crbug.com/638180.\n",
            "Trace/breakpoint trap (core dumped)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تشغيل أمر الإعداد المدمج مع التطبيق\n",
        "!~/.lmstudio/bin/lms bootstrap\n",
        "\n",
        "# إضافة المسار إلى متغيرات البيئة الحالية\n",
        "import os\n",
        "os.environ['PATH'] += \":/root/.lmstudio/bin\"\n",
        "\n",
        "# التحقق من أن الأمر يعمل بشكل صحيح\n",
        "!lms status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejaa1WwXz3jU",
        "outputId": "f52fe79f-2053-4b32-b662-4c595c53257a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /root/.lmstudio/bin/lms: No such file or directory\n",
            "/bin/bash: line 1: lms: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# بدء تشغيل الخادم\n",
        "!lms server start\n",
        "\n",
        "# تحميل نموذج صغير للتجربة\n",
        "!lms download \"TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF\" --file \"tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\"\n",
        "\n",
        "# تحميل النموذج في الذاكرة\n",
        "!lms load \"TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/tinyllama-1.1b-chat-v1.0.q4_k_m.gguf\""
      ],
      "metadata": {
        "id": "8H_obz-cz7jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تشغيل التطبيق مع وسيطة --no-sandbox لتجاوز خطأ صلاحيات root\n",
        "!xvfb-run --auto-servernum ./LM-Studio.AppImage --no-sandbox &\n",
        "# الانتظار لمدة 60 ثانية لإعطاء التطبيق وقتاً كافياً للتهيئة\n",
        "!sleep 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEWQQl7T0WNF",
        "outputId": "c2cd199b-5892-4c09-9cf4-6934567757b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7435:1022/024831.323880:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
            "[7435:1022/024834.158619:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
            "[7435:1022/024834.158705:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
            "[7435:1022/024834.194117:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[7435:1022/024834.194625:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[7435:1022/024834.194681:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[7435:1022/024834.194699:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[7435:1022/024834.194720:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.config/LM Studio/settings.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/credentials/lmstudio-hub.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/artifact-permissions-list.json\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Extracting esbuild from /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/esbuild to /root/.lmstudio/.internal/utils/esbuild\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Setting permissions of /root/.lmstudio/.internal/utils/esbuild to 755\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Extracting node from /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/node to /root/.lmstudio/.internal/utils/node\n",
            "[7495:1022/024834.960903:ERROR:components/viz/service/main/viz_main_impl.cc:184] Exiting GPU process due to errors during initialization\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Setting permissions of /root/.lmstudio/.internal/utils/node to 755\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Extracting deno from /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/deno to /root/.lmstudio/.internal/utils/deno\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Setting permissions of /root/.lmstudio/.internal/utils/deno to 755\n",
            "\u001b[97m[ProcessForkingProvider]\u001b[39m Using NodeProcessForker\n",
            "Forking systemresourcesworker: isDevBuild: false, isElectron: true\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7540\u001b[39m\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/backend-preferences-v1.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/internal-engine-index.json\n",
            "\u001b[36m02:48:36.825\u001b[0m ›\u001b[0m App starting...\n",
            "\u001b[36m02:48:36.846\u001b[0m ›\u001b[0m [AppUpdater] Update channel set to 'stable'\n",
            "\u001b[97m[LmsProvider]\u001b[39m Extracting lms from /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/lms to /root/.lmstudio/bin/lms\n",
            "\u001b[97m[LmsProvider]\u001b[39m Extracted lms successfully\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/http-server-config.json\n",
            "\u001b[97m[FileData]\u001b[39m Initializing FileData\n",
            "\u001b[97m[FileData]\u001b[39m File does not exist, writing default data\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/permissions-store.json\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7551\u001b[39m\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Exited process \u001b[33m7551\u001b[39m\n",
            "\u001b[97m[SystemResourcesProvider]\u001b[39m [performHardwareSurvey] Failed to perform hardware survey with bundled 'vulkan' liblmstudio. Error: LMSCore process using library '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/liblmstudio/vulkan/liblmstudio_bindings_vulkan.node' exited unexpectedly on command 'survey-hardware' with code: null, stack: Error\n",
            "    at Proxy._0x4ece81 (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:114:28308)\n",
            "    at Object.onceWrapper (node:events:633:26)\n",
            "    at _0x1547d0.emit (node:events:530:35)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:104:211882)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:114:27096)\n",
            "    at _0x440042.<anonymous> (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:104:211203)\n",
            "    at _0x440042.emit (node:events:530:35)\n",
            "    at ChildProcess.<anonymous> (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:608:21181)\n",
            "    at ChildProcess.emit (node:events:518:28)\n",
            "    at ChildProcess._handle.onexit (node:internal/child_process:293:12)\n",
            "\u001b[33m02:48:37.657\u001b[0m ›\u001b[0m Failed to perform general hardware survey with bundled 'vulkan' LMSCore library. Error: Failed to perform hardware survey with bundled 'vulkan' liblmstudio. Error: LMSCore process using library '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/liblmstudio/vulkan/liblmstudio_bindings_vulkan.node' exited unexpectedly on command 'survey-hardware' with code: null, stack: Error\n",
            "    at Proxy._0x4ece81 (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:114:28308)\n",
            "    at Object.onceWrapper (node:events:633:26)\n",
            "    at _0x1547d0.emit (node:events:530:35)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:104:211882)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:114:27096)\n",
            "    at _0x440042.<anonymous> (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:104:211203)\n",
            "    at _0x440042.emit (node:events:530:35)\n",
            "    at ChildProcess.<anonymous> (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:608:21181)\n",
            "    at ChildProcess.emit (node:events:518:28)\n",
            "    at ChildProcess._handle.onexit (node:internal/child_process:293:12)\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7558\u001b[39m\n",
            "\u001b[97m[SystemResourcesProvider]\u001b[39m Hardware survey successfully achieved through bundled 'cpu' liblmstudio.\n",
            "\u001b[36m02:48:37.708\u001b[0m ›\u001b[0m Hardware survey for general system resources through 'cpu' took 49.12ms\n",
            "\u001b[36m02:48:37.719\u001b[0m ›\u001b[0m Hardware survey for general system resources through  'gpu shell' took 10.91ms\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7567\u001b[39m\n",
            "\u001b[97m[OpenaiInputOutputProcessingProvider]\u001b[39m Derive function running, frameworks: \u001b[33m0\u001b[39m\n",
            "\u001b[97m[OpenaiInputOutputProcessingProvider]\u001b[39m No compatible frameworks found for domain openaiInputOutputProcessing.\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/model-data.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/hardware-config.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/runtime-selections.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/document-parsing-cache-v1.json\n",
            "App is ready\n",
            "[7435:1022/024837.806429:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[7435:1022/024837.822839:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
            "[7435:1022/024837.837191:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/global-plugin-configs.json\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Unbundling plugin lmstudio/rag-v1 (revision #5) from tarball bundled-plugin-rag-v1.tar.gz.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Unbundling plugin lmstudio/js-code-sandbox (revision #7) from tarball bundled-plugin-js-code-sandbox.tar.gz.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Indexing installed plugins.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Found new installed plugin: lmstudio/js-code-sandbox\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Found new installed plugin: lmstudio/rag-v1\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/mcp.json\n",
            "\u001b[97m[LMSInternal][Client=LM Studio]\u001b[39m Client created.\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/conversation-config.json\n",
            "\u001b[97m[ConversationsProvider]\u001b[39m No chat found. Creating a new chat.\n",
            "\u001b[36m02:48:38.509\u001b[0m ›\u001b[0m [AppUpdater] Checking for updates... (current state: idle)\n",
            "\u001b[36m02:48:38.510\u001b[0m ›\u001b[0m AppUpdater state changed to checking-for-updates-periodic\n",
            "\u001b[36m02:48:38.511\u001b[0m ›\u001b[0m [AppUpdater] Fetching version info from https://versions-prod.lmstudio.ai/update/linux/x86/0.3.30\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/persistent-extension-pack-state.json\n",
            "App is ready\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Injecting dependencies...\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Successfully injected 39 dependencies in 0.89ms.\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Start calling onInjected()...\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Finished calling onInjected()...\n",
            "\u001b[97m[LMSInternal][Client=plugin:builtin:lmstudio/default-prediction-loop-handler]\u001b[39m Client created.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Failed to obtain API server port for plugin connection. Error: API Server port not set. Either the API server has not started or it has failed to obtain an available port.\n",
            "    at _0x555e52.<computed>.obtainApiServerPort (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:121:19656)\n",
            "    at _0x2bfc4f.getPluginConnectionHostPort (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:543:41972)\n",
            "    at _0x2bfc4f.getPluginConnectionBaseUrl (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:543:42234)\n",
            "    at _0x2bfc4f.addUnmanagedPlugin (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:543:35505)\n",
            "    at Object.handler (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:308:577)\n",
            "    at _0xdfdaee.receivedChannelCreate (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:1041:489)\n",
            "    at <computed> [as receivedMessage] (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:1024:14262)\n",
            "    at _0x221a1b.subscriber (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:1024:10783)\n",
            "    at _0x221a1b.notifier (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:926:197469)\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider][Watcher-0]\u001b[39m Sync: Subscribing to /root/.config/LM Studio\n",
            "\u001b[97m[   PredictionLoopHandler]\u001b[39m Register with LM Studio\n",
            "\u001b[97m[LMSInternal][Client=plugin:builtin:lmstudio/default-prediction-loop-handler][Endpoint=setPredictionLoopHandler]\u001b[39m Registering prediction loop handler.\n",
            "\u001b[97m[FileWatchingProvider][Watcher-1]\u001b[39m Sync: Subscribing to /root/.lmstudio\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "[7435:1022/024838.689864:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "Preload script prod path /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/main_window_preload.js\n",
            "[7435:1022/024838.904977:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "process.env.NODE_ENV production\n",
            "\u001b[36m02:48:39.329\u001b[0m ›\u001b[0m [AppUpdater] Received version info response\n",
            "\u001b[36m02:48:39.330\u001b[0m ›\u001b[0m [AppUpdater] Current version: 0.3.30 (build: 2), new version: 0.3.30 (build: 2)\n",
            "\u001b[36m02:48:39.331\u001b[0m ›\u001b[0m No update available: 0.3.30 (build: 2) <= 0.3.30 (build: 2)\n",
            "\u001b[36m02:48:39.332\u001b[0m ›\u001b[0m AppUpdater state changed to idle\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: data initialization\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: autoStartServer\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: ModelIndexProvider\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: Unbundle dependencies\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Unbundling engines from the app installer... (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends -> /root/.lmstudio/extensions/backends)\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: DocumentParsingWarmup\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: initialMCPSync\n",
            "\u001b[97m[MCPProvider]\u001b[39m Start updating MCP servers.\n",
            "\u001b[97m[MCPProvider]\u001b[39m Update plan { removedMCPServerNames: [], addedServers: [] }\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: LoginItemSync\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: startAPIServer\n",
            "\u001b[97m[APIServerProvider]\u001b[39m Trying to start the API Server on port: \u001b[33m41343\u001b[39m\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: initial fetch feed\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: Perform initial chat indexing\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: Refresh backends master list\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Indexing installed plugins.\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m Directory added: /root/.lmstudio/models\n",
            "\u001b[97m[APIServerProvider]\u001b[39m API Server started on port: \u001b[33m41343\u001b[39m\n",
            "\u001b[97m[ModelIndexProvider][Op-1]\u001b[39m Requested to index directory: /root/.lmstudio/models\n",
            "\u001b[97m[ModelIndexProvider][Op-1]\u001b[39m Starting indexing operation on directory: /root/.lmstudio/models\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m Directory added: /root/.lmstudio/hub/models\n",
            "[7435:1022/024839.781372:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[ModelIndexProvider][Op-2]\u001b[39m Requested to index directory: /root/.lmstudio/hub/models\n",
            "\u001b[97m[ModelIndexProvider][Op-2]\u001b[39m Starting indexing operation on directory: /root/.lmstudio/hub/models\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m Directory added: /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/bundled-models\n",
            "[7435:1022/024839.806254:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[ModelIndexProvider][Op-3]\u001b[39m Requested to index directory: /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/bundled-models\n",
            "\u001b[97m[ModelIndexProvider][Op-3]\u001b[39m Starting indexing operation on directory: /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/bundled-models\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider][Watcher-2]\u001b[39m Sync: Subscribing to /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/bundled-models\n",
            "\u001b[97m[ConversationsSearchProvider]\u001b[39m Indexing completed in \u001b[33m103.11730299999908\u001b[39m ms\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m File deleted, reading data. Path: /root/.lmstudio/.internal/artifact-permissions-list.json\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Indexing installed plugins.\n",
            "\u001b[97m[GGUFMetadataProvider]\u001b[39m Reading GGUF metadata for /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/bundled-models/nomic-ai/nomic-embed-text-v1.5-GGUF/nomic-embed-text-v1.5.Q4_K_M.gguf took 484ms\n",
            "[7435:1022/024840.585263:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[MCPProvider]\u001b[39m Update plan applied\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/ui-state/global.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/ui-state/window-1.json\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python' -> 'python3.11' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3' -> 'python3.11' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3-config' -> 'python3.11-config' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3-config'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3-embed.pc' -> 'python-3.11-embed.pc' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3-embed.pc'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3.pc' -> 'python-3.11.pc' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3.pc'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/libpython3.11.so' -> 'libpython3.11.so.1.0' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/libpython3.11.so'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/share/man/man1/python3.1' -> 'python3.11.1' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/share/man/man1/python3.1'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/bin/python_' -> '../../cpython3.11-linux-x86@2/bin/python' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/bin/python_'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/bin/python3' -> 'python' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/bin/python3'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/bin/python3.11' -> 'python' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/bin/python3.11'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/lib64' -> 'lib' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/lib64'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/linux-llama-cuda-vendor-v1/libcublas.so.11' -> 'libcublas.so.11.11.3.6' created at '/root/.lmstudio/extensions/backends/vendor/linux-llama-cuda-vendor-v1/libcublas.so.11'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/linux-llama-cuda-vendor-v1/libcublasLt.so.11' -> 'libcublasLt.so.11.11.3.6' created at '/root/.lmstudio/extensions/backends/vendor/linux-llama-cuda-vendor-v1/libcublasLt.so.11'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/linux-llama-cuda-vendor-v1/libcudart.so.11.0' -> 'libcudart.so.11.8.89' created at '/root/.lmstudio/extensions/backends/vendor/linux-llama-cuda-vendor-v1/libcudart.so.11.0'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/linux-llama-vulkan-vendor-v1/libvulkan.so' -> 'libvulkan.so.1.3.204' created at '/root/.lmstudio/extensions/backends/vendor/linux-llama-vulkan-vendor-v1/libvulkan.so'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/backends/vendor/linux-llama-vulkan-vendor-v1/libvulkan.so.1' -> 'libvulkan.so.1.3.204' created at '/root/.lmstudio/extensions/backends/vendor/linux-llama-vulkan-vendor-v1/libvulkan.so.1'\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished unbundling engines from the app installer. [54068.66 ms], hasAnythingMoved: true\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Unbundling frameworks from the app installer... (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/bin/extensions/frameworks -> /root/.lmstudio/extensions/frameworks)\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished unbundling frameworks from the app installer. [40.48 ms], hasAnythingMoved: true\n",
            "\u001b[97m[BackendDownloadProvider]\u001b[39m Auto-updating backend harmony-linux-x86_64-avx2:0.3.4\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5...\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Executing Python command:  /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python -I /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/postinstall.py\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5. [1847.32 ms]\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2...\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Executing Python command:  /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python -I /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/postinstall.py\n",
            "\u001b[97m[RuntimeIndexerTarGzExtractionPostDownloadActionExecutor]\u001b[39m Extracting tar.gz files...\n",
            "\u001b[97m[amphibianUtils]\u001b[39m stdout: *** Error compiling '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/Tix8.4.3/pref/WmDefault.py'...\n",
            "Sorry: TabError: inconsistent use of tabs and spaces in indentation (WmDefault.py, line 86)\n",
            "\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2. [13322.51 ms]\n",
            "\u001b[97m[BackendManager]\u001b[39m Performing backend hardware survey...\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m Framework harmony-linux-x86_64-avx2-0.3.4 requires vendor lib _amphibian/app-harmony-linux-x86@5, but it is not installed.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying hardware with backends with options: {\"type\":\"newAndSelected\"}\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying new engine 'llama.cpp-linux-x86_64-avx2@1.52.1'\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7876\u001b[39m\n",
            "\u001b[31m02:49:47.329\u001b[0m ›\u001b[0m \u001b[97m[amphibianUtils]\u001b[39m Error getting Python path for amphibian runtime layer: Error: Failed to parse venvstacks for /root/.lmstudio/extensions/backends/vendor/_amphibian/.tmp-1335414158218: ENOENT: no such file or directory, open '/root/.lmstudio/extensions/backends/vendor/_amphibian/.tmp-1335414158218/share/venv/metadata/venvstacks_layer.json'\n",
            "    at _0x1cc559 (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:20111)\n",
            "    at async _0x4a78e0 (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:20453)\n",
            "    at async _0x2f892b.isAmphibianLayer (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:12608)\n",
            "    at async _0x46483e (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:8852)\n",
            "    at async _0x46483e (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:8775)\n",
            "    at async _0x1bd3e5.indexVendorLibs (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:9235)\n",
            "    at async _0x1bd3e5.reindexVendorLibs (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:9569)\n",
            "    at async _0x1bd3e5.performInitialIndex (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:10263)\n",
            "    at async Promise.all (index 0)\n",
            "    at async /tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:912:27045\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m Vendor installation target /root/.lmstudio/extensions/backends/vendor/_amphibian/.tmp-1335414158218 is broken. Error: Amphibian layer is marked for deletion: /root/.lmstudio/extensions/backends/vendor/_amphibian/.tmp-1335414158218\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m Vendor installation target /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5 is broken. Error: Post-install files not found for amphibian application layer: /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5\n",
            "\u001b[97m[BackendManager]\u001b[39m Survey for engine 'llama.cpp-linux-x86_64-avx2@1.52.1' took 240.45ms\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying new engine 'llama.cpp-linux-x86_64-nvidia-cuda-avx2@1.52.1'\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m Framework harmony-linux-x86_64-avx2-0.3.4 requires vendor lib _amphibian/app-harmony-linux-x86@5, but it is not installed.\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7884\u001b[39m\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Exited process \u001b[33m7876\u001b[39m\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Exited process \u001b[33m7884\u001b[39m\n",
            "\u001b[33m02:49:47.680\u001b[0m ›\u001b[0m Failed to survey hardware with engine 'llama.cpp-linux-x86_64-nvidia-cuda-avx2@1.52.1': LMSCore load lib failed - child process with PID 7884 exited with code 1\n",
            "\u001b[97m[BackendManager]\u001b[39m Survey for engine 'llama.cpp-linux-x86_64-nvidia-cuda-avx2@1.52.1' took 174.70ms\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying new engine 'llama.cpp-linux-x86_64-vulkan-avx2@1.52.1'\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7891\u001b[39m\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m File deleted, reading data. Path: /root/.lmstudio/.internal/persistent-extension-pack-state.json\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Exited process \u001b[33m7891\u001b[39m\n",
            "\u001b[33m02:49:47.894\u001b[0m ›\u001b[0m Failed to survey hardware with engine 'llama.cpp-linux-x86_64-vulkan-avx2@1.52.1': LMSCore process using library '/root/.lmstudio/extensions/backends/llama.cpp-linux-x86_64-vulkan-avx2-1.52.1/liblmstudio_bindings_vulkan.node' exited unexpectedly on command 'survey-hardware' with code: null, stack: Error\n",
            "    at Proxy._0x4ece81 (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:114:28308)\n",
            "    at Object.onceWrapper (node:events:633:26)\n",
            "    at _0x1547d0.emit (node:events:530:35)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:104:211882)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:114:27096)\n",
            "    at _0x440042.<anonymous> (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:104:211203)\n",
            "    at _0x440042.emit (node:events:530:35)\n",
            "    at ChildProcess.<anonymous> (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:608:21181)\n",
            "    at ChildProcess.emit (node:events:518:28)\n",
            "    at ChildProcess._handle.onexit (node:internal/child_process:293:12)\n",
            "\u001b[97m[BackendManager]\u001b[39m Survey for engine 'llama.cpp-linux-x86_64-vulkan-avx2@1.52.1' took 212.21ms\n",
            "\u001b[97m[BackendManager]\u001b[39m Updating backend preferences file at '/root/.lmstudio/.internal/backend-preferences-v1.json' for current environment...\n",
            "\u001b[97m[BackendManager]\u001b[39m Adding 'llama.cpp-linux-x86_64-avx2' to backend prefs for model format 'gguf'\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m Backend preferences file set for the first time: [{\"model_format\":\"gguf\",\"name\":\"llama.cpp-linux-x86_64-avx2\",\"version\":\"1.52.1\"}]. Setting as last preferences for subscription.\n",
            "\u001b[97m[BackendManager]\u001b[39m Backend preferences file update complete\n",
            "\u001b[97m[BackendDownloadProvider]\u001b[39m Auto-updating backend llama.cpp-linux-x86_64-avx2:1.53.1\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Upgrading selected runtimes...\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Finding latest version for runtime: llama.cpp-linux-x86_64-avx2\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Matching versions found: 1.52.1\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Latest version found: 1.52.1\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init after UI: plugins init load\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Init loading lmstudio/js-code-sandbox.\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/js-code-sandbox]\u001b[39m Client created.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Init loading lmstudio/rag-v1.\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/rag-v1]\u001b[39m Client created.\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m File deleted, reading data. Path: /root/.lmstudio/.internal/backend-preferences-v1.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m File deleted, reading data. Path: /root/.lmstudio/.internal/internal-engine-index.json\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[InternalPluginsProvider][PluginProcess(lmstudio/js-code-sandbox)]\u001b[39m stdout: [Tools Prvdr.] Register with LM Studio\n",
            "\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/js-code-sandbox][Endpoint=setToolsProvider]\u001b[39m Registering tools provider.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Evicting plugin lmstudio/js-code-sandbox.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Unload requested\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Force exiting plugin process.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Plugin process force exited.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Unloaded\n",
            "\u001b[97m[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[97m[InternalPluginsProvider][PluginProcess(lmstudio/rag-v1)]\u001b[39m stdout: [PromptPreprocessor] Register with LM Studio\n",
            "\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/rag-v1][Endpoint=setPromptPreprocessor]\u001b[39m Registering promptPreprocessor.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Evicting plugin lmstudio/rag-v1.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Unload requested\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Force exiting plugin process.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Plugin process force exited.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Unloaded\n",
            "\u001b[97m[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[RuntimeIndexerTarGzExtractionPostDownloadActionExecutor]\u001b[39m Post-download tar.gz extraction took 17616.68369099999ms\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Executing Python command:  /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python -I /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5/postinstall.py\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2\n",
            "\u001b[97m[RuntimeIndexerTarGzExtractionPostDownloadActionExecutor]\u001b[39m Failed to run python layer post install script. Skipping postinstall. Error: Amphibian layer is marked for deletion: /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2\n",
            "    at _0x2f892b.runAmphibianPostInstallScript (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:295:13064)\n",
            "    at async _0xa1b558.handleAmphibianPostInstall (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:262:5183)\n",
            "    at async _0xa1b558.execute (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:262:4979)\n",
            "    at async _0x4926c2.finishDownloadJob (/tmp/.mount_LM-StuKXqbhj/resources/app/.webpack/main/index.js:256:3401)\n",
            "\u001b[97m[LockDebounceTaskQueue]\u001b[39m Executing debounced task. Processed 14 requests, executing only the final one.\n",
            "\u001b[97m[extensionPackAutoDeletion]\u001b[39m Protecting 1 versions of harmony-linux-x86_64-avx2 from auto-deletion: 0.3.4\n",
            "\u001b[97m[BackendDownloadProvider]\u001b[39m Auto-updating backend harmony-linux-x86_64-avx2:0.3.4 completed\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m Skipping index vendor lib at path '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2' due to deletion marker.\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m Framework harmony-linux-x86_64-avx2-0.3.4 requires vendor lib _amphibian/cpython3.11-linux-x86@2, but it is not installed.\n",
            "\u001b[97m[RuntimeIndexerTarGzExtractionPostDownloadActionExecutor]\u001b[39m Extracting tar.gz files...\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m ----> Extension packs to resurvey: [{\"name\":\"harmony-linux-x86_64-avx2\",\"version\":\"0.3.4\"}]\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m File watcher emitted change events for vendor libs folder, queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: []\n",
            "\u001b[97m[RuntimeIndexerTarGzExtractionPostDownloadActionExecutor]\u001b[39m Post-download tar.gz extraction took 390.4746740000119ms\n",
            "\u001b[97m[IndexLockDebounceQueue]\u001b[39m Executing debounced runtime index tasks.\n",
            "\u001b[97m[LockDebounceTaskQueue]\u001b[39m Executing debounced task. Processed 1 requests, executing only the final one.\n",
            "\u001b[97m[IndexLockDebounceQueue]\u001b[39m Executing debounced runtime index tasks.\n",
            "\u001b[97m[BackendManager]\u001b[39m No engine resurvey requested, returning cached engine index results...\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m Framework harmony-linux-x86_64-avx2-0.3.4 requires vendor lib _amphibian/cpython3.11-linux-x86@2, but it is not installed.\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m Detected change in backend preferences for model format 'gguf'. Running hardware survey...\n",
            "\u001b[97m[BackendManager]\u001b[39m Performing backend hardware survey...\n",
            "\u001b[97m[extensionPackAutoDeletion]\u001b[39m Protecting 2 versions of llama.cpp-linux-x86_64-avx2 from auto-deletion: 1.53.1, 1.52.1\n",
            "\u001b[97m[BackendDownloadProvider]\u001b[39m Auto-updating backend llama.cpp-linux-x86_64-avx2:1.53.1 completed\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying hardware with backends with options: {\"type\":\"custom\",\"extPacksToReindex\":[{\"name\":\"llama.cpp-linux-x86_64-avx2\",\"version\":\"1.53.1\"}]}\n",
            "\u001b[97m[BackendManager]\u001b[39m Performing custom requested engine-hardware survey for engine 'llama.cpp-linux-x86_64-avx2@1.53.1'\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7947\u001b[39m\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m File watcher emitted change events for folder queueing a debounce-able re-index\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: .tmp-1352075461254\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: llama.cpp-linux-x86_64-avx2-1.53.1\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m     --------> candidateExtPackName: llama.cpp-linux-x86_64-avx2-1.53.1\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m ----> Extension packs to resurvey: [{\"name\":\"llama.cpp-linux-x86_64-avx2\",\"version\":\"1.53.1\"}]\n",
            "\u001b[97m[IndexLockDebounceQueue]\u001b[39m Executing debounced runtime index tasks.\n",
            "\u001b[97m[BackendManager]\u001b[39m Survey for engine 'llama.cpp-linux-x86_64-avx2@1.53.1' took 214.94ms\n",
            "\u001b[97m[BackendManager]\u001b[39m Updating backend preferences file at '/root/.lmstudio/.internal/backend-preferences-v1.json' for current environment...\n",
            "\u001b[97m[BackendManager]\u001b[39m Backend preferences file update complete\n",
            "\u001b[97m[BackendManager]\u001b[39m Performing backend hardware survey...\n",
            "\u001b[97m[VendorLibIndexProvider]\u001b[39m Skipping index vendor lib at path '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2' due to deletion marker.\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying hardware with backends with options: {\"type\":\"custom\",\"extPacksToReindex\":[{\"name\":\"llama.cpp-linux-x86_64-avx2\",\"version\":\"1.53.1\"}]}\n",
            "\u001b[97m[BackendManager]\u001b[39m Performing custom requested engine-hardware survey for engine 'llama.cpp-linux-x86_64-avx2@1.53.1'\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m7958\u001b[39m\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m Framework harmony-linux-x86_64-avx2-0.3.4 requires vendor lib _amphibian/cpython3.11-linux-x86@2, but it is not installed.\n",
            "\u001b[97m[BackendManager]\u001b[39m Survey for engine 'llama.cpp-linux-x86_64-avx2@1.53.1' took 198.51ms\n",
            "\u001b[97m[BackendManager]\u001b[39m Updating backend preferences file at '/root/.lmstudio/.internal/backend-preferences-v1.json' for current environment...\n",
            "\u001b[97m[BackendManager]\u001b[39m Backend preferences file update complete\n",
            "[7435:1022/025822.595402:FATAL:electron/shell/browser/electron_browser_main_parts.cc:501] Failed to shutdown.\n",
            "[7518:1022/025822.634171:ERROR:ui/gfx/x/connection.cc:65] X connection error received.\n",
            "[7518:1022/025822.634196:ERROR:ui/gfx/x/connection.cc:65] X connection error received.\n",
            "Trace/breakpoint trap (core dumped)\n",
            "yes\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تشغيل أمر الإعداد المدمج مع التطبيق\n",
        "!~/.lmstudio/bin/lms bootstrap\n",
        "\n",
        "# إضافة المسار إلى متغيرات البيئة الحالية\n",
        "import os\n",
        "os.environ['PATH'] += \":/root/.lmstudio/bin\"\n",
        "\n",
        "# التحقق من أن الأمر يعمل بشكل صحيح\n",
        "!lms status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w9rfAqU0WiO",
        "outputId": "d4c8c9db-6227-404d-9f0f-e056c832adbb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m  ✓ Already Installed  \u001b[39m\n",
            "\n",
            "LM Studio CLI tool is already installed for the following shells:\n",
            "\n",
            "\u001b[96m    · sh \u001b[90m(~/.profile)\u001b[39m\u001b[96m\u001b[39m\n",
            "\u001b[96m    · bash \u001b[90m(~/.bashrc)\u001b[39m\u001b[96m\u001b[39m\n",
            "\n",
            "If your shell is not listed above, please try to add the following directory to the PATH environment variable:\n",
            "\n",
            "    \u001b[93m/root/.lmstudio/bin\u001b[39m\n",
            "\n",
            "  \u001b[90m(i) If you are having trouble running the CLI tool, please open a new terminal. and try again.\u001b[39m\n",
            "Server: \u001b[31m OFF \u001b[39m\n",
            "\n",
            "\u001b[90m(i) To start the server, run the following command:\u001b[39m\n",
            "\n",
            "    lms server start\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/root/.lmstudio/bin lms server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEE4msSt2-R9",
        "outputId": "a6d84361-da3d-4ae3-a83a-eb7058227e21"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /root/.lmstudio/bin: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/.lmstudio/bin && lms server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rjCl0_R3FzO",
        "outputId": "5c00eb9c-ea0f-4853-d842-e7a0b9598f09"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/root/.lmstudio/bin && lms server start'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lms server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5pkPdb93NQ2",
        "outputId": "06923a5f-26cd-4932-ab9f-7ea9f71f0920"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waking up LM Studio service...\n",
            "node:events:496\n",
            "      throw er; // Unhandled 'error' event\n",
            "      ^\n",
            "\n",
            "Error: spawn /tmp/.mount_LM-StuKXqbhj/lm-studio ENOENT\n",
            "\u001b[90m    at ChildProcess._handle.onexit (node:internal/child_process:286:19)\u001b[39m\n",
            "\u001b[90m    at onErrorNT (node:internal/child_process:484:16)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n",
            "Emitted 'error' event on ChildProcess instance at:\n",
            "\u001b[90m    at ChildProcess._handle.onexit (node:internal/child_process:292:12)\u001b[39m\n",
            "\u001b[90m    at onErrorNT (node:internal/child_process:484:16)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m {\n",
            "  errno: \u001b[33m-2\u001b[39m,\n",
            "  code: \u001b[32m'ENOENT'\u001b[39m,\n",
            "  syscall: \u001b[32m'spawn /tmp/.mount_LM-StuKXqbhj/lm-studio'\u001b[39m,\n",
            "  path: \u001b[32m'/tmp/.mount_LM-StuKXqbhj/lm-studio'\u001b[39m,\n",
            "  spawnargs: [ \u001b[32m'--run-as-service'\u001b[39m ]\n",
            "}\n",
            "\n",
            "Node.js v20.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# الخطوة 5 (مُعدّلة): بدء تشغيل الخادم بشكل صحيح\n",
        "\n",
        "!echo \"INFO: Starting LM Studio application in the background...\"\n",
        "# أولاً: نقوم بتشغيل التطبيق الرئيسي في الخلفية. هذا سيعيد إنشاء المجلد المؤقت.\n",
        "!xvfb-run --auto-servernum ./LM-Studio.AppImage --no-sandbox &\n",
        "\n",
        "!echo \"INFO: Waiting 15 seconds for the application to initialize...\"\n",
        "# ثانياً: ننتظر قليلاً (15 ثانية كافية) للتأكد من أن التطبيق قد بدأ بالفعل.\n",
        "!sleep 15\n",
        "\n",
        "!echo \"INFO: Sending command to start the server...\"\n",
        "# ثالثاً: الآن بعد أن أصبح التطبيق يعمل، نرسل له أمر بدء الخادم.\n",
        "!lms server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQwajrpg3iQ-",
        "outputId": "187f5878-8868-446f-e54a-db8ea610af3c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Starting LM Studio application in the background...\n",
            "[11734:1022/030517.780417:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
            "[11734:1022/030520.972608:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
            "[11734:1022/030520.972702:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
            "[11734:1022/030521.020981:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[11734:1022/030521.021188:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[11734:1022/030521.021459:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[11734:1022/030521.021701:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[11734:1022/030521.021730:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.config/LM Studio/settings.json\n",
            "\u001b[97m[VersionMigrationProvider]\u001b[39m Last recorded app version: v0.3.30-b2\n",
            "\u001b[97m[VersionMigrationProvider]\u001b[39m Current app version: v0.3.30-b2\n",
            "\u001b[97m[VersionMigrationProvider]\u001b[39m No app version update detected.\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/credentials/lmstudio-hub.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/artifact-permissions-list.json\n",
            "\u001b[97m[UtilsProvider]\u001b[39m esbuild already exists at /root/.lmstudio/.internal/utils/esbuild, comparing sizes.\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Sizes match, skipping extraction of esbuild\n",
            "\u001b[97m[UtilsProvider]\u001b[39m node already exists at /root/.lmstudio/.internal/utils/node, comparing sizes.\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Sizes match, skipping extraction of node\n",
            "\u001b[97m[UtilsProvider]\u001b[39m deno already exists at /root/.lmstudio/.internal/utils/deno, comparing sizes.\n",
            "\u001b[97m[UtilsProvider]\u001b[39m Sizes match, skipping extraction of deno\n",
            "\u001b[97m[ProcessForkingProvider]\u001b[39m Using NodeProcessForker\n",
            "Forking systemresourcesworker: isDevBuild: false, isElectron: true\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m11811\u001b[39m\n",
            "[11797:1022/030521.867588:ERROR:components/viz/service/main/viz_main_impl.cc:184] Exiting GPU process due to errors during initialization\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/backend-preferences-v1.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/internal-engine-index.json\n",
            "\u001b[36m03:05:22.178\u001b[0m ›\u001b[0m App starting...\n",
            "\u001b[36m03:05:22.186\u001b[0m ›\u001b[0m [AppUpdater] Update channel set to 'stable'\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/http-server-config.json\n",
            "\u001b[97m[FileData]\u001b[39m Initializing FileData\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/permissions-store.json\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m11845\u001b[39m\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Exited process \u001b[33m11845\u001b[39m\n",
            "\u001b[97m[SystemResourcesProvider]\u001b[39m [performHardwareSurvey] Failed to perform hardware survey with bundled 'vulkan' liblmstudio. Error: LMSCore process using library '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/liblmstudio/vulkan/liblmstudio_bindings_vulkan.node' exited unexpectedly on command 'survey-hardware' with code: null, stack: Error\n",
            "    at Proxy._0x4ece81 (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:114:28308)\n",
            "    at Object.onceWrapper (node:events:633:26)\n",
            "    at _0x1547d0.emit (node:events:530:35)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:104:211882)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:114:27096)\n",
            "    at _0x440042.<anonymous> (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:104:211203)\n",
            "    at _0x440042.emit (node:events:530:35)\n",
            "    at ChildProcess.<anonymous> (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:608:21181)\n",
            "    at ChildProcess.emit (node:events:518:28)\n",
            "    at ChildProcess._handle.onexit (node:internal/child_process:293:12)\n",
            "\u001b[33m03:05:22.299\u001b[0m ›\u001b[0m Failed to perform general hardware survey with bundled 'vulkan' LMSCore library. Error: Failed to perform hardware survey with bundled 'vulkan' liblmstudio. Error: LMSCore process using library '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/liblmstudio/vulkan/liblmstudio_bindings_vulkan.node' exited unexpectedly on command 'survey-hardware' with code: null, stack: Error\n",
            "    at Proxy._0x4ece81 (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:114:28308)\n",
            "    at Object.onceWrapper (node:events:633:26)\n",
            "    at _0x1547d0.emit (node:events:530:35)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:104:211882)\n",
            "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:114:27096)\n",
            "    at _0x440042.<anonymous> (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:104:211203)\n",
            "    at _0x440042.emit (node:events:530:35)\n",
            "    at ChildProcess.<anonymous> (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:608:21181)\n",
            "    at ChildProcess.emit (node:events:518:28)\n",
            "    at ChildProcess._handle.onexit (node:internal/child_process:293:12)\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m11852\u001b[39m\n",
            "\u001b[97m[SystemResourcesProvider]\u001b[39m Hardware survey successfully achieved through bundled 'cpu' liblmstudio.\n",
            "\u001b[36m03:05:22.369\u001b[0m ›\u001b[0m Hardware survey for general system resources through 'cpu' took 69.00ms\n",
            "\u001b[36m03:05:22.382\u001b[0m ›\u001b[0m Hardware survey for general system resources through  'gpu shell' took 13.00ms\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m11861\u001b[39m\n",
            "\u001b[97m[OpenaiInputOutputProcessingProvider]\u001b[39m Derive function running, frameworks: \u001b[33m0\u001b[39m\n",
            "\u001b[97m[OpenaiInputOutputProcessingProvider]\u001b[39m No compatible frameworks found for domain openaiInputOutputProcessing.\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/model-data.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/hardware-config.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/runtime-selections.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/document-parsing-cache-v1.json\n",
            "App is ready\n",
            "[11734:1022/030522.671825:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "[11734:1022/030522.686316:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
            "[11734:1022/030522.717275:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/global-plugin-configs.json\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Skipping unbundling of plugin lmstudio/rag-v1 as it is already unbundled and has a revision (#5) greater than or equal to the bundled plugin revision (#5).\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Skipping unbundling of plugin lmstudio/js-code-sandbox as it is already unbundled and has a revision (#7) greater than or equal to the bundled plugin revision (#7).\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Indexing installed plugins.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Found new installed plugin: lmstudio/js-code-sandbox\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Found new installed plugin: lmstudio/rag-v1\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/mcp.json\n",
            "\u001b[97m[LMSInternal][Client=LM Studio]\u001b[39m Client created.\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/conversation-config.json\n",
            "\u001b[36m03:05:22.888\u001b[0m ›\u001b[0m [AppUpdater] Checking for updates... (current state: idle)\n",
            "\u001b[36m03:05:22.889\u001b[0m ›\u001b[0m AppUpdater state changed to checking-for-updates-periodic\n",
            "\u001b[36m03:05:22.890\u001b[0m ›\u001b[0m [AppUpdater] Fetching version info from https://versions-prod.lmstudio.ai/update/linux/x86/0.3.30\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/persistent-extension-pack-state.json\n",
            "App is ready\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Injecting dependencies...\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Successfully injected 39 dependencies in 1.34ms.\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Start calling onInjected()...\n",
            "\u001b[97m[DependencyInjectionContext]\u001b[39m Finished calling onInjected()...\n",
            "\u001b[97m[LMSInternal][Client=plugin:builtin:lmstudio/default-prediction-loop-handler]\u001b[39m Client created.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Failed to obtain API server port for plugin connection. Error: API Server port not set. Either the API server has not started or it has failed to obtain an available port.\n",
            "    at _0x555e52.<computed>.obtainApiServerPort (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:121:19656)\n",
            "    at _0x2bfc4f.getPluginConnectionHostPort (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:543:41972)\n",
            "    at _0x2bfc4f.getPluginConnectionBaseUrl (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:543:42234)\n",
            "    at _0x2bfc4f.addUnmanagedPlugin (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:543:35505)\n",
            "    at Object.handler (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:308:577)\n",
            "    at _0xdfdaee.receivedChannelCreate (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:1041:489)\n",
            "    at <computed> [as receivedMessage] (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:1024:14262)\n",
            "    at _0x221a1b.subscriber (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:1024:10783)\n",
            "    at _0x221a1b.notifier (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/index.js:926:197469)\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider][Watcher-0]\u001b[39m Sync: Subscribing to /root/.config/LM Studio\n",
            "\u001b[97m[   PredictionLoopHandler]\u001b[39m Register with LM Studio\n",
            "\u001b[97m[LMSInternal][Client=plugin:builtin:lmstudio/default-prediction-loop-handler][Endpoint=setPredictionLoopHandler]\u001b[39m Registering prediction loop handler.\n",
            "\u001b[97m[FileWatchingProvider][Watcher-1]\u001b[39m Sync: Subscribing to /root/.lmstudio\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "[11734:1022/030523.228458:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "Preload script prod path /tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/main/main_window_preload.js\n",
            "[11734:1022/030523.530750:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
            "process.env.NODE_ENV production\n",
            "\u001b[36m03:05:23.981\u001b[0m ›\u001b[0m [AppUpdater] Received version info response\n",
            "\u001b[36m03:05:23.985\u001b[0m ›\u001b[0m [AppUpdater] Current version: 0.3.30 (build: 2), new version: 0.3.30 (build: 2)\n",
            "\u001b[36m03:05:23.987\u001b[0m ›\u001b[0m No update available: 0.3.30 (build: 2) <= 0.3.30 (build: 2)\n",
            "\u001b[36m03:05:23.990\u001b[0m ›\u001b[0m AppUpdater state changed to idle\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: data initialization\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: update lms\n",
            "\u001b[97m[LmsProvider]\u001b[39m Extracting lms from /tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/lms to /root/.lmstudio/bin/lms\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: autoStartServer\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: ModelIndexProvider\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: Unbundle dependencies\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Unbundling engines from the app installer... (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends -> /root/.lmstudio/extensions/backends)\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: DocumentParsingWarmup\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: initialMCPSync\n",
            "\u001b[97m[MCPProvider]\u001b[39m Start updating MCP servers.\n",
            "\u001b[97m[MCPProvider]\u001b[39m Update plan { removedMCPServerNames: [], addedServers: [] }\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: LoginItemSync\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: startAPIServer\n",
            "\u001b[97m[APIServerProvider]\u001b[39m Trying to start the API Server on port: \u001b[33m41343\u001b[39m\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: initial fetch feed\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: Perform initial chat indexing\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init: Refresh backends master list\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Indexing installed plugins.\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m Directory added: /root/.lmstudio/models\n",
            "\u001b[97m[APIServerProvider]\u001b[39m API Server started on port: \u001b[33m41343\u001b[39m\n",
            "\u001b[97m[ModelIndexProvider][Op-1]\u001b[39m Requested to index directory: /root/.lmstudio/models\n",
            "\u001b[97m[ModelIndexProvider][Op-1]\u001b[39m Starting indexing operation on directory: /root/.lmstudio/models\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m Directory added: /root/.lmstudio/hub/models\n",
            "[11734:1022/030524.325702:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[ModelIndexProvider][Op-2]\u001b[39m Requested to index directory: /root/.lmstudio/hub/models\n",
            "\u001b[97m[ModelIndexProvider][Op-2]\u001b[39m Starting indexing operation on directory: /root/.lmstudio/hub/models\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m Directory added: /tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/bundled-models\n",
            "[11734:1022/030524.372988:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[ModelIndexProvider][Op-3]\u001b[39m Requested to index directory: /tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/bundled-models\n",
            "\u001b[97m[ModelIndexProvider][Op-3]\u001b[39m Starting indexing operation on directory: /tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/bundled-models\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider][Watcher-2]\u001b[39m Sync: Subscribing to /tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/bundled-models\n",
            "\u001b[97m[ConversationsSearchProvider]\u001b[39m Indexing completed in \u001b[33m163.5684420000007\u001b[39m ms\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Indexing installed plugins.\n",
            "\u001b[97m[MCPProvider]\u001b[39m Update plan applied\n",
            "\u001b[97m[GGUFMetadataProvider]\u001b[39m Reading GGUF metadata for /tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/bundled-models/nomic-ai/nomic-embed-text-v1.5-GGUF/nomic-embed-text-v1.5.Q4_K_M.gguf took 447ms\n",
            "[11734:1022/030525.388043:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python' -> 'python3.11' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3' -> 'python3.11' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3-config' -> 'python3.11-config' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python3-config'\n",
            "\u001b[97m[LmsProvider]\u001b[39m Extracted lms successfully\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3-embed.pc' -> 'python-3.11-embed.pc' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3-embed.pc'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3.pc' -> 'python-3.11.pc' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/pkgconfig/python3.pc'\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/ui-state/global.json\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/ui-state/window-1.json\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/libpython3.11.so' -> 'libpython3.11.so.1.0' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/libpython3.11.so'\n",
            "\u001b[97m[BundledDepsUnpackager][fsutils]\u001b[39m Symlink '/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/share/man/man1/python3.1' -> 'python3.11.1' created at '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/share/man/man1/python3.1'\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished unbundling engines from the app installer. [25061.51 ms], hasAnythingMoved: true\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Unbundling frameworks from the app installer... (/tmp/.mount_LM-StuHVjFn8/resources/app/.webpack/bin/extensions/frameworks -> /root/.lmstudio/extensions/frameworks)\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished unbundling frameworks from the app installer. [6.93 ms], hasAnythingMoved: true\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5...\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Skipping post-install script execution because pyvenv.cfg already exists\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5. [1.29 ms]\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2...\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2\n",
            "\u001b[97m[amphibianUtils]\u001b[39m Executing Python command:  /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python -I /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/postinstall.py\n",
            "\u001b[97m[amphibianUtils]\u001b[39m stdout: *** Error compiling '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/Tix8.4.3/pref/WmDefault.py'...\n",
            "Sorry: TabError: inconsistent use of tabs and spaces in indentation (WmDefault.py, line 86)\n",
            "\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m ✅ Finished running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2. [3788.83 ms]\n",
            "\u001b[97m[BackendManager]\u001b[39m Performing backend hardware survey...\n",
            "\u001b[97m[LockDebounceTaskQueue]\u001b[39m Executing debounced task. Processed 1 requests, executing only the final one.\n",
            "\u001b[97m[FrameworkIndexProvider]\u001b[39m Framework harmony-linux-x86_64-avx2-0.3.4 requires vendor lib _amphibian/app-harmony-linux-x86@5, but it is not installed.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying hardware with backends with options: {\"type\":\"newAndSelected\"}\n",
            "\u001b[97m[BackendManager]\u001b[39m Skipping resurvey of engine 'llama.cpp-linux-x86_64-avx2@1.52.1'. Reason: not selected\n",
            "\u001b[97m[BackendManager]\u001b[39m Surveying selected engine 'llama.cpp-linux-x86_64-avx2@1.53.1'\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m12015\u001b[39m\n",
            "\u001b[97m[BackendManager]\u001b[39m Survey for engine 'llama.cpp-linux-x86_64-avx2@1.53.1' took 116.66ms\n",
            "\u001b[97m[BackendManager]\u001b[39m Skipping resurvey of engine 'llama.cpp-linux-x86_64-nvidia-cuda-avx2@1.52.1'. Reason: not selected\n",
            "\u001b[97m[BackendManager]\u001b[39m Skipping resurvey of engine 'llama.cpp-linux-x86_64-vulkan-avx2@1.52.1'. Reason: not selected\n",
            "\u001b[97m[BackendManager]\u001b[39m Updating backend preferences file at '/root/.lmstudio/.internal/backend-preferences-v1.json' for current environment...\n",
            "\u001b[97m[RuntimeIndexProvider]\u001b[39m Backend preferences file set for the first time: [{\"model_format\":\"gguf\",\"name\":\"llama.cpp-linux-x86_64-avx2\",\"version\":\"1.53.1\"}]. Setting as last preferences for subscription.\n",
            "\u001b[97m[BackendManager]\u001b[39m Backend preferences file update complete\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Start syncing file watching provider... Changes may be missed during this process.\n",
            "\u001b[97m[FileWatchingProvider]\u001b[39m Sync completed.\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Upgrading selected runtimes...\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Finding latest version for runtime: llama.cpp-linux-x86_64-avx2\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Matching versions found: 1.52.1, 1.53.1\n",
            "\u001b[97m[BundledDepsUnpackager]\u001b[39m Latest version found: 1.53.1\n",
            "\u001b[97m[DelayedInitProvider]\u001b[39m Running delayed init after UI: plugins init load\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Init loading lmstudio/js-code-sandbox.\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/js-code-sandbox]\u001b[39m Client created.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Init loading lmstudio/rag-v1.\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/rag-v1]\u001b[39m Client created.\n",
            "\u001b[97m[InternalPluginsProvider][PluginProcess(lmstudio/js-code-sandbox)]\u001b[39m stdout: [Tools Prvdr.] Register with LM Studio\n",
            "\n",
            "\u001b[97m[InternalPluginsProvider][PluginProcess(lmstudio/rag-v1)]\u001b[39m stdout: [PromptPreprocessor] Register with LM Studio\n",
            "\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/js-code-sandbox][Endpoint=setToolsProvider]\u001b[39m Registering tools provider.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Evicting plugin lmstudio/js-code-sandbox.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Unload requested\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Force exiting plugin process.\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/rag-v1][Endpoint=setPromptPreprocessor]\u001b[39m Registering promptPreprocessor.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Plugin process force exited.\n",
            "\u001b[97m[InternalPluginsProvider]\u001b[39m Evicting plugin lmstudio/rag-v1.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Unload requested\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Force exiting plugin process.\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)]\u001b[39m Unloaded\n",
            "\u001b[97m[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Plugin process force exited.\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=plugin:installed:lmstudio/rag-v1]\u001b[39m Client disconnected.\n",
            "\u001b[97m[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[97m[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)]\u001b[39m Unloaded\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client created.\n",
            "[11734:1022/030743.762675:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "[11734:1022/030743.786007:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client disconnected.\n",
            "\u001b[97m[SystemExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m File deleted, reading data. Path: /root/.lmstudio/.internal/http-server-config.json\n",
            "[11734:1022/030743.896629:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client created.\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=searchModels]\u001b[39m Searching models: { searchTerm: \u001b[32m'llama-3.1-8b'\u001b[39m }\n",
            "\u001b[97m[SearchProvider]\u001b[39m Expanding search term llama-3.1-8b\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=getModelDownloadOptions]\u001b[39m Getting model download options: {\n",
            "  type: \u001b[32m'catalog'\u001b[39m,\n",
            "  identifier: \u001b[32m'lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF'\u001b[39m\n",
            "}\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=downloadModel]\u001b[39m Start downloading: modelDownload:huggingface:lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF:lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m File change detected: create /root/.lmstudio/models/lmstudio-community\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m File change detected: create /root/.lmstudio/models/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\n",
            "\u001b[97m[ModelIndexProvider][Op-4]\u001b[39m Requested to index directory: /root/.lmstudio/models\n",
            "\u001b[97m[ModelIndexProvider][Op-4]\u001b[39m Starting indexing operation on directory: /root/.lmstudio/models\n",
            "[11734:1022/031205.336051:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=downloadModel]\u001b[39m Download completed, waiting for model to be indexed...\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m File deleted, reading data. Path: /root/.lmstudio/.internal/model-data.json\n",
            "\u001b[97m[ModelIndexProvider]\u001b[39m File change detected: create /root/.lmstudio/models/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
            "\u001b[97m[ModelIndexProvider][Op-5]\u001b[39m Requested to index directory: /root/.lmstudio/models\n",
            "\u001b[97m[ModelIndexProvider][Op-5]\u001b[39m Starting indexing operation on directory: /root/.lmstudio/models\n",
            "\u001b[97m[GGUFMetadataProvider]\u001b[39m Reading GGUF metadata for /root/.lmstudio/models/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf took 3855ms\n",
            "[11734:1022/031613.983629:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client disconnected.\n",
            "\u001b[97m[RepositoryExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client created.\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=listDownloadedModels]\u001b[39m Listing downloaded models\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=loadModel]\u001b[39m Loading model: lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
            "\u001b[97m[ModelLoadingProvider]\u001b[39m Requested to load model lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf with opts {\n",
            "  instanceLoadTimeConfig: { fields: [] },\n",
            "  identifier: { desired: \u001b[32m'meta-llama-3.1-8b-instruct'\u001b[39m, conflictBehavior: \u001b[32m'bump'\u001b[39m },\n",
            "  ttlMs: \u001b[90mundefined\u001b[39m,\n",
            "  cancelEvent: _0x221a1b { subscriber: \u001b[1mnull\u001b[22m, queued: [], isNotifying: \u001b[33mfalse\u001b[39m }\n",
            "}\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/user-concrete-model-default-config/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf.json\n",
            "\u001b[97m[ModelLoadingProvider]\u001b[39m Estimate to use 5928073634.88 bytes when loaded. (model: 5068361343.04, context: 859712291.84) Previous estimation: 6889034835.2 bytes.\n",
            "\u001b[97m[ModelLoadingProvider]\u001b[39m Started loading model lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
            "\u001b[97m[ModelProxyObject(id=meta-llama-3.1-8b-instruct)]\u001b[39m Forking LLMWorker with custom envVars: {}\n",
            "\u001b[97m[ProcessForkingProvider][NodeProcessForker]\u001b[39m Spawned process \u001b[33m15219\u001b[39m\n",
            "[11734:1022/031950.207104:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=getModelInfo]\u001b[39m Getting descriptor for specifier: {\"type\":\"instanceReference\",\"instanceReference\":\"LPkM6H8Uu5Wt4pZTS8avPDX5\"}\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client disconnected.\n",
            "\u001b[97m[SystemExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[97m[LLMExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client created.\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=listDownloadedModels]\u001b[39m Listing downloaded models\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli][Endpoint=listLoaded]\u001b[39m Listing loaded models\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=lms-cli]\u001b[39m Client disconnected.\n",
            "\u001b[97m[SystemExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[97m[LLMExternalAPIProvider][WsServer:AuthenticatedWsServer]\u001b[39m Terminating connection because authentication was revoked\n",
            "\u001b[94mD\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=4d148e2a-43cc-46ce-810d-a8769cba5ed8]\u001b[39m Client created.\n",
            "\u001b[92mI\u001b[39m \u001b[97m[LMSExternal]\u001b[39m \u001b[97m[Client=4d148e2a-43cc-46ce-810d-a8769cba5ed8][Endpoint=getOrLoad]\u001b[39m Requested get or load model: meta-llama-3.1-8b-instruct\n",
            "\u001b[97m[CachedFileDataProvider]\u001b[39m Watching file at /root/.lmstudio/.internal/user-concrete-model-default-config/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf.json\n",
            "[11734:1022/032820.164760:FATAL:electron/shell/browser/electron_browser_main_parts.cc:501] Failed to shutdown.\n",
            "[11831:1022/032820.175449:ERROR:ui/gfx/x/connection.cc:65] X connection error received.\n",
            "[11831:1022/032820.174272:ERROR:ui/gfx/x/connection.cc:65] X connection error received.\n",
            "Trace/breakpoint trap (core dumped)\n",
            "INFO: Waiting 15 seconds for the application to initialize...\n",
            "lms\n",
            "INFO: Sending command to start the server...\n",
            "Waking up LM Studio service...\n",
            "node:events:496\n",
            "      throw er; // Unhandled 'error' event\n",
            "      ^\n",
            "\n",
            "Error: spawn /tmp/.mount_LM-StuHVjFn8/lm-studio ENOENT\n",
            "\u001b[90m    at ChildProcess._handle.onexit (node:internal/child_process:286:19)\u001b[39m\n",
            "\u001b[90m    at onErrorNT (node:internal/child_process:484:16)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n",
            "Emitted 'error' event on ChildProcess instance at:\n",
            "\u001b[90m    at ChildProcess._handle.onexit (node:internal/child_process:292:12)\u001b[39m\n",
            "\u001b[90m    at onErrorNT (node:internal/child_process:484:16)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m {\n",
            "  errno: \u001b[33m-2\u001b[39m,\n",
            "  code: \u001b[32m'ENOENT'\u001b[39m,\n",
            "  syscall: \u001b[32m'spawn /tmp/.mount_LM-StuHVjFn8/lm-studio'\u001b[39m,\n",
            "  path: \u001b[32m'/tmp/.mount_LM-StuHVjFn8/lm-studio'\u001b[39m,\n",
            "  spawnargs: [ \u001b[32m'--run-as-service'\u001b[39m ]\n",
            "}\n",
            "\n",
            "Node.js v20.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /root/.lmstudio/bin && ./lms server start"
      ],
      "metadata": {
        "id": "CxkRgCMY4H6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lms download \"TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF\" --file \"tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X5MjxxF5AZG",
        "outputId": "764a35ff-8b1d-485f-a42d-4b12ca3ee517"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: unknown command 'download'\n",
            "(Did you mean unload?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "termenal\n",
        "\n",
        "\n",
        " cd /root/.lmstudio/bin && ./lms get llama-3.1-8b"
      ],
      "metadata": {
        "id": "i6_3W8dp5Bgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /root/.lmstudio/bin && ./lms load meta-llama-3.1-8b-instruct"
      ],
      "metadata": {
        "id": "4U2MpeDB7OK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lmstudio as lms\n",
        "\n",
        "model = lms.llm(\"qwen/qwen3-4b-2507\")\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "7SN_uKgm7rij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /root/.lmstudio/bin && ./lms ls"
      ],
      "metadata": {
        "id": "DdVuAYI178NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "⠧ [███████████████████████████████████████████\n",
        "Model loaded successfully in 52.20s. (4.92 GB)\n",
        "To use the model in the API/SDK, use the identifier \"meta-llama-3.1-8b-instruct\".\n",
        "To set a custom identifier, use the --identifier <identifier> option.\n",
        "~/.lmstudio/bin# python\n",
        "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0] on linux\n",
        "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
        ">>> import lmstudio as lms\n",
        ">>> exit()\n",
        "~/.lmstudio/bin# import lmstudio as lms ls\n",
        "-bash: import: command not found\n",
        "~/.lmstudio/bin# cd /root/.lmstudio/bin && ./lms ls\n",
        "\n",
        "You have 2 models, taking up 5.00 GB of disk space.\n",
        "\n",
        "LLM                           PARAMS    ARCH     SIZE\n",
        "meta-llama-3.1-8b-instruct    8B        Llama    4.92 GB    ✓ LOADED\n",
        "\n",
        "EMBEDDING                               PARAMS    ARCH          SIZE\n",
        "text-embedding-nomic-embed-text-v1.5              Nomic BERT    84.11 MB\n",
        "\n",
        "~/.lmstudio/bin#"
      ],
      "metadata": {
        "id": "gRZv7Y138PX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://lmstudio.ai/docs/cli/get"
      ],
      "metadata": {
        "id": "c63H7uB98U_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lmstudio as lms\n",
        "\n",
        "model = lms.llm(\"meta-llama-3.1-8b-instruct\")\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "0yzd6QK484uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "~/.lmstudio/bin# python\n",
        "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0] on linux\n",
        "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>> import lmstudio as lms\n",
        ">>>\n",
        ">>> model = lms.llm(\"meta-llama-3.1-8b-instruct\")\n",
        ">>> result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "\n",
        "[0] 0:python3*  \"aad8f5b2ad77\" 03:26 22-Oct-25"
      ],
      "metadata": {
        "id": "ds85XE7Z9J80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "~/.lmstudio/bin# python\n",
        "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0] on linux\n",
        "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>>\n",
        ">>> import lmstudio as lms\n",
        ">>>\n",
        ">>> model = lms.llm(\"meta-llama-3.1-8b-instruct\")\n",
        ">>> result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "\n",
        "[0] 0:python3*  \"aad8f5b2ad77\" 03:26 22-Oct-25"
      ],
      "metadata": {
        "id": "QU5YgUp19ocM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# الخطوة 5 (مُعدّلة): بدء تشغيل الخادم بشكل صحيح\n",
        "\n",
        "!echo \"INFO: Starting LM Studio application in the background...\"\n",
        "# أولاً: نقوم بتشغيل التطبيق الرئيسي في الخلفية. هذا سيعيد إنشاء المجلد المؤقت.\n",
        "!xvfb-run --auto-servernum ./LM-Studio.AppImage --no-sandbox &\n",
        "\n",
        "!echo \"INFO: Waiting 15 seconds for the application to initialize...\"\n",
        "# ثانياً: ننتظر قليلاً (15 ثانية كافية) للتأكد من أن التطبيق قد بدأ بالفعل.\n",
        "!sleep 15\n",
        "\n",
        "!echo \"INFO: Sending command to start the server...\"\n",
        "# ثالثاً: الآن بعد أن أصبح التطبيق يعمل، نرسل له أمر بدء الخادم.\n",
        "!lms server start"
      ],
      "metadata": {
        "id": "RCDP789U954E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content"
      ],
      "metadata": {
        "id": "NxK-zEVu-mrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xvfb-run --auto-servernum ./LM-Studio.AppImage --no-sandbox & && lms server start"
      ],
      "metadata": {
        "id": "7TV3NL9k-wVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "termenal\n",
        "\n",
        "\n",
        "\n",
        "content# xvfb-run --auto-servernum ./LM-Studio.AppImage --no-sandbox & && lms server start\n",
        "-bash: syntax error near unexpected token `&&'\n",
        "/content# xvfb-run --auto-servernum ./LM-Studio.AppImage --no-sandbox &\n",
        "[1] 20521\n",
        "/content# [20534:1022/033446.957830:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
        "[20534:1022/033452.479580:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
        "[20534:1022/033452.479741:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
        "[20534:1022/033452.543009:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
        "[20534:1022/033452.548106:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
        "[20534:1022/033452.548152:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
        "[20534:1022/033452.549371:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
        "[20534:1022/033452.549417:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type:\n",
        "[CachedFileDataProvider] Watching file at /root/.config/LM Studio/settings.json\n",
        "[VersionMigrationProvider] Last recorded app version: v0.3.30-b2\n",
        "[VersionMigrationProvider] Current app version: v0.3.30-b2\n",
        "[VersionMigrationProvider] No app version update detected.\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/credentials/lmstudio-hub.json\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/artifact-permissions-list.json\n",
        "[UtilsProvider] esbuild already exists at /root/.lmstudio/.internal/utils/esbuild, comparing sizes.\n",
        "[UtilsProvider] Sizes match, skipping extraction of esbuild\n",
        "[UtilsProvider] node already exists at /root/.lmstudio/.internal/utils/node, comparing sizes.\n",
        "[UtilsProvider] Sizes match, skipping extraction of node\n",
        "[UtilsProvider] deno already exists at /root/.lmstudio/.internal/utils/deno, comparing sizes.\n",
        "[UtilsProvider] Sizes match, skipping extraction of deno\n",
        "[ProcessForkingProvider] Using NodeProcessForker\n",
        "Forking systemresourcesworker: isDevBuild: false, isElectron: true\n",
        "[ProcessForkingProvider][NodeProcessForker] Spawned process 20618\n",
        "[20606:1022/033454.316413:ERROR:components/viz/service/main/viz_main_impl.cc:184] Exiting GPU process due to errors during initialization\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/backend-preferences-v1.json\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/internal-engine-index.json\n",
        "03:34:55.285 › App starting...\n",
        "03:34:55.316 › [AppUpdater] Update channel set to 'stable'\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/http-server-config.json\n",
        "[FileData] Initializing FileData\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/permissions-store.json\n",
        "[ProcessForkingProvider][NodeProcessForker] Spawned process 20651\n",
        "[ProcessForkingProvider][NodeProcessForker] Exited process 20651\n",
        "[SystemResourcesProvider] [performHardwareSurvey] Failed to perform hardware survey with bundled 'vulkan' liblmstudio. Error: LMSCore process using library '/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/liblmstudio/vulkan/liblmstudio_bindings_vulkan.node' exited unexpectedly on command 'survey-hardware' with code: null, stack: Error\n",
        "    at Proxy._0x4ece81 (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:114:28308)\n",
        "    at Object.onceWrapper (node:events:633:26)\n",
        "    at _0x1547d0.emit (node:events:530:35)\n",
        "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:104:211882)\n",
        "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:114:27096)\n",
        "    at _0x440042.<anonymous> (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:104:211203)\n",
        "    at _0x440042.emit (node:events:530:35)\n",
        "    at ChildProcess.<anonymous> (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:608:21181)\n",
        "    at ChildProcess.emit (node:events:518:28)\n",
        "    at ChildProcess._handle.onexit (node:internal/child_process:293:12)\n",
        "03:34:56.154 › Failed to perform general hardware survey with bundled 'vulkan' LMSCore library. Error: Failed to perform hardware survey with bundled 'vulkan' liblmstudio. Error: LMSCore process using library '/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/liblmstudio/vulkan/liblmstudio_bindings_vulkan.node' exited unexpectedly on command 'survey-hardware' with code: null, stack: Error\n",
        "    at Proxy._0x4ece81 (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:114:28308)\n",
        "    at Object.onceWrapper (node:events:633:26)\n",
        "    at _0x1547d0.emit (node:events:530:35)\n",
        "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:104:211882)\n",
        "    at _0x1547d0.onChildExit (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:114:27096)\n",
        "    at _0x440042.<anonymous> (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:104:211203)\n",
        "    at _0x440042.emit (node:events:530:35)\n",
        "    at ChildProcess.<anonymous> (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:608:21181)\n",
        "    at ChildProcess.emit (node:events:518:28)\n",
        "    at ChildProcess._handle.onexit (node:internal/child_process:293:12)\n",
        "[ProcessForkingProvider][NodeProcessForker] Spawned process 20669\n",
        "[SystemResourcesProvider] Hardware survey successfully achieved through bundled 'cpu' liblmstudio.\n",
        "03:34:56.517 › Hardware survey for general system resources through 'cpu' took 330.50ms\n",
        "03:34:56.586 › Hardware survey for general system resources through  'gpu shell' took 61.34ms\n",
        "[ProcessForkingProvider][NodeProcessForker] Spawned process 20682\n",
        "[OpenaiInputOutputProcessingProvider] Derive function running, frameworks: 0\n",
        "[OpenaiInputOutputProcessingProvider] No compatible frameworks found for domain openaiInputOutputProcessing.\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/model-data.json\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/hardware-config.json\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/runtime-selections.json\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/document-parsing-cache-v1.json\n",
        "App is ready\n",
        "[20534:1022/033457.069826:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
        "[20534:1022/033457.108745:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type:\n",
        "[20534:1022/033457.196090:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/global-plugin-configs.json\n",
        "[InternalPluginsProvider] Skipping unbundling of plugin lmstudio/rag-v1 as it is already unbundled and has a revision (#5) greater than or equal to the bundled plugin revision (#5).\n",
        "[InternalPluginsProvider] Skipping unbundling of plugin lmstudio/js-code-sandbox as it is already unbundled and has a revision (#7) greater than or equal to the bundled plugin revision (#7).\n",
        "[InternalPluginsProvider] Indexing installed plugins.\n",
        "[InternalPluginsProvider] Found new installed plugin: lmstudio/js-code-sandbox\n",
        "[InternalPluginsProvider] Found new installed plugin: lmstudio/rag-v1\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/mcp.json\n",
        "[LMSInternal][Client=LM Studio] Client created.\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/conversation-config.json\n",
        "03:34:57.786 › [AppUpdater] Checking for updates... (current state: idle)\n",
        "03:34:57.792 › AppUpdater state changed to checking-for-updates-periodic\n",
        "03:34:57.794 › [AppUpdater] Fetching version info from https://versions-prod.lmstudio.ai/update/linux/x86/0.3.30\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/persistent-extension-pack-state.json\n",
        "App is ready\n",
        "[DependencyInjectionContext] Injecting dependencies...\n",
        "[DependencyInjectionContext] Successfully injected 39 dependencies in 4.74ms.\n",
        "[DependencyInjectionContext] Start calling onInjected()...\n",
        "[DependencyInjectionContext] Finished calling onInjected()...\n",
        "[LMSInternal][Client=plugin:builtin:lmstudio/default-prediction-loop-handler] Client created.\n",
        "[InternalPluginsProvider] Failed to obtain API server port for plugin connection. Error: API Server port not set. Either the API server has not started or it has failed to obtain an available port.\n",
        "    at _0x555e52.<computed>.obtainApiServerPort (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:121:19656)\n",
        "    at _0x2bfc4f.getPluginConnectionHostPort (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:543:41972)\n",
        "    at _0x2bfc4f.getPluginConnectionBaseUrl (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:543:42234)\n",
        "    at _0x2bfc4f.addUnmanagedPlugin (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:543:35505)\n",
        "    at Object.handler (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:308:577)\n",
        "    at _0xdfdaee.receivedChannelCreate (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:1041:489)\n",
        "    at <computed> [as receivedMessage] (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:1024:14262)\n",
        "    at _0x221a1b.subscriber (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:1024:10783)\n",
        "    at _0x221a1b.notifier (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/index.js:926:197469)\n",
        "[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.\n",
        "[FileWatchingProvider][Watcher-0] Sync: Subscribing to /root/.config/LM Studio\n",
        "[   PredictionLoopHandler] Register with LM Studio\n",
        "[LMSInternal][Client=plugin:builtin:lmstudio/default-prediction-loop-handler][Endpoint=setPredictionLoopHandler] Registering prediction loop handler.\n",
        "[FileWatchingProvider][Watcher-1] Sync: Subscribing to /root/.lmstudio\n",
        "03:34:58.920 › [AppUpdater] Received version info response\n",
        "03:34:58.924 › [AppUpdater] Current version: 0.3.30 (build: 2), new version: 0.3.30 (build: 2)\n",
        "03:34:58.938 › No update available: 0.3.30 (build: 2) <= 0.3.30 (build: 2)\n",
        "03:34:58.943 › AppUpdater state changed to idle\n",
        "[FileWatchingProvider] Sync completed.\n",
        "[20534:1022/033459.102398:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "Preload script prod path /tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/main/main_window_preload.js\n",
        "[20534:1022/033459.859271:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
        "process.env.NODE_ENV production\n",
        "[DelayedInitProvider] Running delayed init: data initialization\n",
        "[DelayedInitProvider] Running delayed init: update lms\n",
        "[LmsProvider] Extracting lms from /tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/lms to /root/.lmstudio/bin/lms\n",
        "[DelayedInitProvider] Running delayed init: autoStartServer\n",
        "[DelayedInitProvider] Running delayed init: ModelIndexProvider\n",
        "[DelayedInitProvider] Running delayed init: Unbundle dependencies\n",
        "[BundledDepsUnpackager] Unbundling engines from the app installer... (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/extensions/backends -> /root/.lmstudio/extensions/backends)\n",
        "[DelayedInitProvider] Running delayed init: DocumentParsingWarmup\n",
        "[DelayedInitProvider] Running delayed init: initialMCPSync\n",
        "[MCPProvider] Start updating MCP servers.\n",
        "[MCPProvider] Update plan { removedMCPServerNames: [], addedServers: [] }\n",
        "[DelayedInitProvider] Running delayed init: LoginItemSync\n",
        "[DelayedInitProvider] Running delayed init: startAPIServer\n",
        "[APIServerProvider] Trying to start the API Server on port: 41343\n",
        "[DelayedInitProvider] Running delayed init: initial fetch feed\n",
        "[DelayedInitProvider] Running delayed init: Perform initial chat indexing\n",
        "[DelayedInitProvider] Running delayed init: Refresh backends master list\n",
        "[InternalPluginsProvider] Indexing installed plugins.\n",
        "[ModelIndexProvider] Directory added: /root/.lmstudio/models\n",
        "[APIServerProvider] API Server started on port: 41343\n",
        "[ModelIndexProvider][Op-1] Requested to index directory: /root/.lmstudio/models\n",
        "[ModelIndexProvider][Op-1] Starting indexing operation on directory: /root/.lmstudio/models\n",
        "[ModelIndexProvider] Directory added: /root/.lmstudio/hub/models\n",
        "[ModelIndexProvider][Op-2] Requested to index directory: /root/.lmstudio/hub/models\n",
        "[ModelIndexProvider][Op-2] Starting indexing operation on directory: /root/.lmstudio/hub/models\n",
        "[ModelIndexProvider] Directory added: /tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/bundled-models\n",
        "[20534:1022/033500.814918:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[ConversationsSearchProvider] Indexing completed in 338.10557400000107 ms\n",
        "[ModelIndexProvider][Op-3] Requested to index directory: /tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/bundled-models\n",
        "[ModelIndexProvider][Op-3] Starting indexing operation on directory: /tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/bundled-models\n",
        "[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.\n",
        "[FileWatchingProvider][Watcher-2] Sync: Subscribing to /tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/bundled-models\n",
        "[FileWatchingProvider] Sync completed.\n",
        "[20534:1022/033502.344503:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[InternalPluginsProvider] Indexing installed plugins.\n",
        "[MCPProvider] Update plan applied\n",
        "[GGUFMetadataProvider] Reading GGUF metadata for /tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/bundled-models/nomic-ai/nomic-embed-text-v1.5-GGUF/nomic-embed-text-v1.5.Q4_K_M.gguf took 693ms\n",
        "[20534:1022/033503.262535:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[LmsProvider] Extracted lms successfully\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/ui-state/global.json\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/ui-state/window-1.json\n",
        "[LMSInternal][Client=LM Studio][Endpoint=permissionsStore] Getting permission token store writable signal...\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/conversations/1761101318499.conversation.json\n",
        "[CachedFileDataProvider] File deleted, reading data. Path: /root/.lmstudio/.internal/ui-state/window-1.json\n",
        "[BundledDepsUnpackager] ✅  Finished unbundling engines from the app installer. [20687.24 ms], hasAnythingMoved: true\n",
        "[BundledDepsUnpackager] Unbundling frameworks from the app installer... (/tmp/.mount_LM-StuNdaAHe/resources/app/.webpack/bin/extensions/frameworks -> /root/.lmstudio/extensions/frameworks)\n",
        "[BundledDepsUnpackager] ✅  Finished unbundling frameworks from the app installer. [5.50 ms], hasAnythingMoved: false\n",
        "[BundledDepsUnpackager] Running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5...\n",
        "[amphibianUtils] Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5\n",
        "[amphibianUtils] Skipping post-install script execution because pyvenv.cfg already exists\n",
        "[BundledDepsUnpackager] ✅  Finished running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/app-harmony-linux-x86@5. [4.72 ms]\n",
        "[BundledDepsUnpackager] Running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2...\n",
        "[amphibianUtils] Post-extraction target path: /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2\n",
        "[amphibianUtils] Executing Python command:  /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/bin/python -I /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/postinstall.py\n",
        "[amphibianUtils] stdout: *** Error compiling '/root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2/lib/Tix8.4.3/pref/WmDefault.py'...\n",
        "Sorry: TabError: inconsistent use of tabs and spaces in indentation (WmDefault.py, line 86)\n",
        "\n",
        "[BundledDepsUnpackager] ✅  Finished running post install script for /root/.lmstudio/extensions/backends/vendor/_amphibian/cpython3.11-linux-x86@2. [6285.91 ms]\n",
        "[BackendManager] Performing backend hardware survey...\n",
        "[LockDebounceTaskQueue] Executing debounced task. Processed 1 requests, executing only the final one.\n",
        "[FrameworkIndexProvider] Framework harmony-linux-x86_64-avx2-0.3.4 requires vendor lib _amphibian/app-harmony-linux-x86@5, but it is not installed.\n",
        "[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.\n",
        "[FileWatchingProvider] Sync completed.\n",
        "[BackendManager] Surveying hardware with backends with options: {\"type\":\"newAndSelected\"}\n",
        "[BackendManager] Skipping resurvey of engine 'llama.cpp-linux-x86_64-avx2@1.52.1'. Reason: not selected\n",
        "[BackendManager] Surveying selected engine 'llama.cpp-linux-x86_64-avx2@1.53.1'\n",
        "[ProcessForkingProvider][NodeProcessForker] Spawned process 20835\n",
        "[BackendManager] Survey for engine 'llama.cpp-linux-x86_64-avx2@1.53.1' took 142.85ms\n",
        "[BackendManager] Skipping resurvey of engine 'llama.cpp-linux-x86_64-nvidia-cuda-avx2@1.52.1'. Reason: not selected\n",
        "[BackendManager] Skipping resurvey of engine 'llama.cpp-linux-x86_64-vulkan-avx2@1.52.1'. Reason: not selected\n",
        "[BackendManager] Updating backend preferences file at '/root/.lmstudio/.internal/backend-preferences-v1.json' for current environment...\n",
        "[RuntimeIndexProvider] Backend preferences file set for the first time: [{\"model_format\":\"gguf\",\"name\":\"llama.cpp-linux-x86_64-avx2\",\"version\":\"1.53.1\"}]. Setting as last preferences for subscription.\n",
        "[BackendManager] Backend preferences file update complete\n",
        "[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.\n",
        "[FileWatchingProvider] Sync completed.\n",
        "[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.\n",
        "[FileWatchingProvider] Sync completed.\n",
        "[BundledDepsUnpackager] Upgrading selected runtimes...\n",
        "[BundledDepsUnpackager] Finding latest version for runtime: llama.cpp-linux-x86_64-avx2\n",
        "[BundledDepsUnpackager] Matching versions found: 1.52.1, 1.53.1\n",
        "[BundledDepsUnpackager] Latest version found: 1.53.1\n",
        "[DelayedInitProvider] Running delayed init after UI: plugins init load\n",
        "[InternalPluginsProvider] Init loading lmstudio/js-code-sandbox.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/js-code-sandbox] Client created.\n",
        "[InternalPluginsProvider] Init loading lmstudio/rag-v1.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/rag-v1] Client created.\n",
        "[InternalPluginsProvider][PluginProcess(lmstudio/js-code-sandbox)] stdout: [Tools Prvdr.] Register with LM Studio\n",
        "\n",
        "[InternalPluginsProvider][PluginProcess(lmstudio/rag-v1)] stdout: [PromptPreprocessor] Register with LM Studio\n",
        "\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/js-code-sandbox][Endpoint=setToolsProvider] Registering tools provider.\n",
        "[InternalPluginsProvider] Evicting plugin lmstudio/js-code-sandbox.\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Unload requested\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Force exiting plugin process.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/rag-v1][Endpoint=setPromptPreprocessor] Registering promptPreprocessor.\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Plugin process force exited.\n",
        "[InternalPluginsProvider] Evicting plugin lmstudio/rag-v1.\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Unload requested\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Force exiting plugin process.\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Unloaded\n",
        "[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer] Terminating connection because authentication was revoked\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Plugin process force exited.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/rag-v1] Client disconnected.\n",
        "[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer] Terminating connection because authentication was revoked\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Unloaded\n",
        "D [LMSExternal] [Client=lms-cli] Client created.\n",
        "[20534:1022/033800.818403:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[20534:1022/033800.863763:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "D [LMSExternal] [Client=lms-cli] Client disconnected.\n",
        "[SystemExternalAPIProvider][WsServer:AuthenticatedWsServer] Terminating connection because authentication was revoked\n",
        "D [LMSExternal] [Client=lms-cli] Client created.\n",
        "I [LMSExternal] [Client=lms-cli][Endpoint=createArtifactDownloadPlan] Creating artifact download plan: qwen qwen3-4b-2507\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/models/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF\n",
        "[ModelIndexProvider][Op-4] Requested to index directory: /root/.lmstudio/models\n",
        "[ModelIndexProvider][Op-4] Starting indexing operation on directory: /root/.lmstudio/models\n",
        "[20534:1022/033918.022354:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "\n",
        "[0] 0:bash*     \"aad8f5b2ad77\" 03:40 22-Oct-25"
      ],
      "metadata": {
        "id": "e1v2z8C0ARoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsjaxsnZ-AFM",
        "outputId": "6f85cdb9-dca4-446c-c07e-28f267757bbb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/lmstudio/bin && lms server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igBK5OKA-Ec2",
        "outputId": "e29181cd-2faa-4987-e79b-8ee41f37a2ab"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/root/lmstudio/bin && lms server start'\n",
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv1rvfu6_KhV",
        "outputId": "8193c786-8d62-4537-e38d-6f65534cdc40"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t\t\t    kaggle\t\t      opt\t\t sys\n",
            "boot\t\t\t    lib\t\t\t      proc\t\t tmp\n",
            "content\t\t\t    lib32\t\t      python-apt\t tools\n",
            "cuda-keyring_1.1-1_all.deb  lib64\t\t      python-apt.tar.xz  usr\n",
            "datalab\t\t\t    libx32\t\t      root\t\t var\n",
            "dev\t\t\t    media\t\t      run\n",
            "etc\t\t\t    mnt\t\t\t      sbin\n",
            "home\t\t\t    NGC-DL-CONTAINER-LICENSE  srv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I5GXAXf_RCk",
        "outputId": "62aeae8b-b147-4ac9-990b-a1d9ce3db3cd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "metadata": {
        "id": "ZUh5g28d_T_t"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .lmstudio/bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhE377qZ_V29",
        "outputId": "d9984039-529c-4175-ce11-ca10ce007f6a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.lmstudio/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMRCJwq__gWW",
        "outputId": "47a47c7f-4751-445c-b0df-59a2efa1efa4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lms server start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqy-s8uK_iU1",
        "outputId": "abe2a681-4fbd-4c89-a01e-b0a05c15945f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Server is now running on port 1234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lms get qwen/qwen3-4b-2507"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IO76BYO_ri1",
        "outputId": "9cdd6bcb-a752-485b-d5b8-10cd8b13ea24"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[?25l\r   ⧗ qwen/qwen3-4b-2507 - Pending...\u001b[0K\n",
            "\r\u001b[0K\n",
            "\r\u001b[90m⠏ Resolving download plan...\u001b[39m\u001b[0K\n",
            "\u001b[3A\r   ⧗ qwen/qwen3-4b-2507 - Pending...\u001b[0K\n",
            "\r\u001b[0K\n",
            "\r\u001b[90m⠋ Resolving download plan...\u001b[39m\u001b[0K\n",
            "\u001b[3A\r   ⠴ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\r\u001b[0K\n",
            "\r\u001b[90m⠋ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠴ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠋ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠦ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠙ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠦ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠙ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠧ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠹ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠧ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠹ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠇ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠸ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠇ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠸ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠏ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠼ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   ⠏ qwen/qwen3-4b-2507 \u001b[90m- Resolving...\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠼ Resolving download plan...\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⧗ Concrete Model - Pending...\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠏ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠋ \u001b[90mFinding options based on your system... (0/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠏ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠋ \u001b[90mFinding options based on your system... (0/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠏ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠙ \u001b[90mFinding options based on your system... (0/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠋ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠙ \u001b[90mFinding options based on your system... (0/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠋ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠹ \u001b[90mFinding options based on your system... (0/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠙ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠹ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠙ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠹ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠙ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠸ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠹ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠸ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠹ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠼ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠸ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠼ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠸ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠴ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠼ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠴ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠼ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠦ \u001b[90mFinding options based on your system... (1/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠴ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠦ \u001b[90mFinding options based on your system... (2/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠴ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠦ \u001b[90mFinding options based on your system... (2/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠴ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠦ \u001b[90mFinding options based on your system... (3/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠴ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠦ \u001b[90mFinding options based on your system... (4/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠴ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠧ \u001b[90mFinding options based on your system... (4/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠦ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠧ \u001b[90mFinding options based on your system... (4/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠦ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠇ \u001b[90mFinding options based on your system... (4/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠧ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m ⠇ \u001b[90mFinding options based on your system... (5/5)\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠧ Resolving download plan... (171.01 KB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m \u001b[33m↓ To download:\u001b[39m Qwen3 4B Instruct 2507 Q4_K_M [GGUF] - \u001b[33m2.50 GB\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠧ Resolving download plan... (2.50 GB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m \u001b[33m↓ To download:\u001b[39m Qwen3 4B Instruct 2507 Q4_K_M [GGUF] - \u001b[33m2.50 GB\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[90m⠧ Resolving download plan... (2.50 GB)\u001b[39m\u001b[0K\n",
            "   \u001b[33m↓ To download:\u001b[39m model qwen/qwen3-4b-2507 - \u001b[90m171.01 KB\u001b[39m\u001b[0K\n",
            "   \u001b[90m└\u001b[39m\u001b[90m─\u001b[39m \u001b[33m↓ To download:\u001b[39m Qwen3 4B Instruct 2507 Q4_K_M [GGUF] - \u001b[33m2.50 GB\u001b[39m\u001b[0K\n",
            "\u001b[0K\n",
            "\u001b[33mAbout to download 2.50 GB.\u001b[39m\u001b[0K\n",
            "\u001b[?25h\u001b[1G\u001b[0JContinue? (Y/N): \u001b[18GY\n",
            "⠼ [██████████████████████] 99.78% |   2.49 GB / 2.50 GB |             4.32 MB/s | ETA 00:01          \u001b[u\u001b[2K\u001b[1G\u001b[?25hFinalizing download...\n",
            "Download completed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://lmstudio.ai/docs/python"
      ],
      "metadata": {
        "id": "gUb5JAJSAjSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmstudio"
      ],
      "metadata": {
        "id": "sC6-szbBAdvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lmstudio as lms\n",
        "\n",
        "model = lms.llm(\"qwen/qwen3-4b-2507\")\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "479kdXjt_y0t",
        "outputId": "ebf2d44f-88e5-4981-e007-fe5623fdf12e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LMStudioRuntimeError",
          "evalue": "Local API host port is not yet resolved.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLMStudioRuntimeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3478192561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlmstudio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"qwen/qwen3-4b-2507\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrespond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is the meaning of life?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLMStudioRuntimeError\u001b[0m: Local API host port is not yet resolved."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a48cfbe0"
      },
      "source": [
        "# Restart the Python runtime to ensure environment changes are picked up.\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linux-x86_64-avx2@1.53.1' took 142.85ms\n",
        "[BackendManager] Skipping resurvey of engine 'llama.cpp-linux-x86_64-nvidia-cuda-avx2@1.52.1'. Reason: not selected\n",
        "[BackendManager] Skipping resurvey of engine 'llama.cpp-linux-x86_64-vulkan-avx2@1.52.1'. Reason: not selected\n",
        "[BackendManager] Updating backend preferences file at '/root/.lmstudio/.internal/backend-preferences-v1.json' for current environment...\n",
        "[RuntimeIndexProvider] Backend preferences file set for the first time: [{\"model_format\":\"gguf\",\"name\":\"llama.cpp-linux-x86_64-avx2\",\"version\":\"1.53.1\"}]. Setting as last preferences for subscription.\n",
        "[BackendManager] Backend preferences file update complete\n",
        "[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.\n",
        "[FileWatchingProvider] Sync completed.\n",
        "[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.\n",
        "[FileWatchingProvider] Sync completed.\n",
        "[BundledDepsUnpackager] Upgrading selected runtimes...\n",
        "[BundledDepsUnpackager] Finding latest version for runtime: llama.cpp-linux-x86_64-avx2\n",
        "[BundledDepsUnpackager] Matching versions found: 1.52.1, 1.53.1\n",
        "[BundledDepsUnpackager] Latest version found: 1.53.1\n",
        "[DelayedInitProvider] Running delayed init after UI: plugins init load\n",
        "[InternalPluginsProvider] Init loading lmstudio/js-code-sandbox.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/js-code-sandbox] Client created.\n",
        "[InternalPluginsProvider] Init loading lmstudio/rag-v1.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/rag-v1] Client created.\n",
        "[InternalPluginsProvider][PluginProcess(lmstudio/js-code-sandbox)] stdout: [Tools Prvdr.] Register with LM Studio\n",
        "\n",
        "[InternalPluginsProvider][PluginProcess(lmstudio/rag-v1)] stdout: [PromptPreprocessor] Register with LM Studio\n",
        "\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/js-code-sandbox][Endpoint=setToolsProvider] Registering tools provider.\n",
        "[InternalPluginsProvider] Evicting plugin lmstudio/js-code-sandbox.\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Unload requested\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Force exiting plugin process.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/rag-v1][Endpoint=setPromptPreprocessor] Registering promptPreprocessor.\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Plugin process force exited.\n",
        "[InternalPluginsProvider] Evicting plugin lmstudio/rag-v1.\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Unload requested\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Force exiting plugin process.\n",
        "[InternalPluginsProvider][PluginInstance(id=1,identifier=lmstudio/js-code-sandbox)] Unloaded\n",
        "[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer] Terminating connection because authentication was revoked\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Plugin process force exited.\n",
        "D [LMSExternal] [Client=plugin:installed:lmstudio/rag-v1] Client disconnected.\n",
        "[PluginsExternalAPIProvider][WsServer:AuthenticatedWsServer] Terminating connection because authentication was revoked\n",
        "[InternalPluginsProvider][PluginInstance(id=2,identifier=lmstudio/rag-v1)] Unloaded\n",
        "D [LMSExternal] [Client=lms-cli] Client created.\n",
        "[20534:1022/033800.818403:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[20534:1022/033800.863763:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "D [LMSExternal] [Client=lms-cli] Client disconnected.\n",
        "[SystemExternalAPIProvider][WsServer:AuthenticatedWsServer] Terminating connection because authentication was revoked\n",
        "D [LMSExternal] [Client=lms-cli] Client created.\n",
        "I [LMSExternal] [Client=lms-cli][Endpoint=createArtifactDownloadPlan] Creating artifact download plan: qwen qwen3-4b-2507\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[SearchProvider] No runtime found for modelCompatibilityType safetensors, defaulting to willNotFit.\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/models/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF\n",
        "[ModelIndexProvider][Op-4] Requested to index directory: /root/.lmstudio/models\n",
        "[ModelIndexProvider][Op-4] Starting indexing operation on directory: /root/.lmstudio/models\n",
        "[20534:1022/033918.022354:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/models/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF/Qwen3-4B-Instruct-2507-Q4_K_M.gguf\n",
        "[ModelIndexProvider][Op-5] Requested to index directory: /root/.lmstudio/models\n",
        "[ModelIndexProvider][Op-5] Starting indexing operation on directory: /root/.lmstudio/models\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/hub/models/qwen\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/hub/models/qwen/.tmp-4923855350641\n",
        "[ModelIndexProvider][Op-6] Requested to index directory: /root/.lmstudio/hub/models\n",
        "[ModelIndexProvider][Op-6] Starting indexing operation on directory: /root/.lmstudio/hub/models\n",
        "[20534:1022/034926.035818:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/hub/models/qwen/.tmp-4923855350641/model.yaml\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/hub/models/qwen/.tmp-4923855350641/README.md\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/hub/models/qwen/.tmp-4923855350641/thumbnail.png\n",
        "[ModelIndexProvider][Op-7] Requested to index directory: /root/.lmstudio/hub/models\n",
        "[ModelIndexProvider][Op-7] Starting indexing operation on directory: /root/.lmstudio/hub/models\n",
        "[20534:1022/034926.068526:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[ModelIndexProvider] File change detected: update /root/.lmstudio/hub/models/qwen/.tmp-4923855350641/thumbnail.png\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/hub/models/qwen/.tmp-4923855350641/manifest.json\n",
        "[ModelIndexProvider] File change detected: delete /root/.lmstudio/hub/models/qwen/.tmp-4923855350641\n",
        "[ModelIndexProvider] File change detected: create /root/.lmstudio/hub/models/qwen/qwen3-4b-2507\n",
        "[ModelIndexProvider][Op-8] Requested to index directory: /root/.lmstudio/hub/models\n",
        "[ModelIndexProvider][Op-8] Starting indexing operation on directory: /root/.lmstudio/hub/models\n",
        "[GGUFMetadataProvider] Reading GGUF metadata for /root/.lmstudio/models/lmstudio-community/Qwen3-4B-Instruct-2507-GGUF/Qwen3-4B-Instruct-2507-Q4_K_M.gguf took 2370ms\n",
        "[20534:1022/034928.439702:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[20534:1022/034928.470941:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "D [LMSExternal] [Client=lms-cli] Client disconnected.\n",
        "[RepositoryExternalAPIProvider][WsServer:AuthenticatedWsServer] Terminating connection because authentication was revoked\n",
        "D [LMSExternal] [Client=d23a5be8-409e-42f6-8d57-dfb743320135] Client created.\n",
        "I [LMSExternal] [Client=d23a5be8-409e-42f6-8d57-dfb743320135][Endpoint=getOrLoad] Requested get or load model: qwen/qwen3-4b-2507\n",
        "D [LMSExternal] [Client=d23a5be8-409e-42f6-8d57-dfb743320135][Endpoint=getOrLoad] Model not found by identifier. Trying to load.\n",
        "[ModelLoadingProvider] Requested to load model qwen/qwen3-4b-2507 with opts {\n",
        "  instanceLoadTimeConfig: { fields: [] },\n",
        "  identifier: { desired: 'qwen/qwen3-4b-2507', conflictBehavior: 'error' },\n",
        "  ttlMs: 3600000,\n",
        "  isJIT: true,\n",
        "  cancelEvent: _0x221a1b { subscriber: null, queued: [], isNotifying: false }\n",
        "}\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/user-concrete-model-default-config/qwen/qwen3-4b-2507.json\n",
        "[ModelLoadingProvider] Estimate to use 3267120753.9100003 bytes when loaded. (model: 2572383545.59, context: 694737208.32) Previous estimation: 3496443654.2 bytes.\n",
        "[ModelLoadingProvider] Started loading model qwen/qwen3-4b-2507\n",
        "[ModelProxyObject(id=qwen/qwen3-4b-2507)] Forking LLMWorker with custom envVars: {}\n",
        "[ProcessForkingProvider][NodeProcessForker] Spawned process 24659\n",
        "[20534:1022/035118.645334:ERROR:content/browser/browser_main_loop.cc:278] Gtk: gtk_widget_add_accelerator: assertion 'GTK_IS_ACCEL_GROUP (accel_group)' failed\n",
        "[CachedFileDataProvider] Watching file at /root/.lmstudio/.internal/user-concrete-model-default-config/qwen/qwen3-4b-2507.json"
      ],
      "metadata": {
        "id": "Caju2U82DCBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8472fc01",
        "outputId": "e8be2eab-2d53-4670-9659-b3098da44e38"
      },
      "source": [
        "import lmstudio as lms\n",
        "\n",
        "# Connect to the LM Studio server\n",
        "# Assuming the server is running on the default port 1234\n",
        "# If you configured a different port, update this line\n",
        "model = lms.llm(\"qwen/qwen3-4b-2507\")\n",
        "\n",
        "# Test the model\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question \"What is the meaning of life?\" is one of the most profound and enduring questions in human history. There is no single, universally accepted answer—because meaning is deeply personal and shaped by culture, religion, philosophy, science, and individual experience.\n",
            "\n",
            "Here are several perspectives on the meaning of life:\n",
            "\n",
            "1. **Philosophical Perspectives**  \n",
            "   - **Existentialism** (e.g., Sartre, Camus): Life has no inherent meaning; it is up to each individual to create their own purpose through choices and actions.  \n",
            "   - **Absurdism** (e.g., Camus): The conflict between the human search for meaning and the universe's apparent silence or randomness is absurd—but we can still find value through living authentically despite that absurdity.  \n",
            "   - **Humanism**: Meaning comes from human values—love, creativity, knowledge, and contributing to society.\n",
            "\n",
            "2. **Religious and Spiritual Views**  \n",
            "   - **Christianity, Islam, Judaism**: Life has meaning because it is a gift from a divine being, and the purpose is to live according to God’s will, love others, and prepare for an afterlife.  \n",
            "   - **Buddhism**: The purpose of life is to attain enlightenment and end suffering through wisdom, compassion, and ethical living.  \n",
            "   - **Hinduism**: Life is part of a cycle (samsara), and the ultimate goal is to achieve moksha (liberation) through dharma, karma, and devotion.  \n",
            "\n",
            "3. **Scientific Perspective**  \n",
            "   - From a biological standpoint, life's purpose may be to survive, reproduce, and pass on genes.  \n",
            "   - From a cosmic view, life may be a natural byproduct of the universe's complexity and evolution—meaning is not something \"out there\" but something we construct through experience.\n",
            "\n",
            "4. **Personal Meaning**  \n",
            "   Many people find meaning in relationships, achievements, service to others, creativity, or personal growth. As Viktor Frankl (a Holocaust survivor and psychiatrist) wrote in *Man’s Search for Meaning*, even in suffering, people find purpose through what they value and what they do—such as love, duty, or responsibility.\n",
            "\n",
            "💡 In short:  \n",
            "**The meaning of life is not something discovered in a single moment or a textbook answer. It is something you build through your experiences, relationships, choices, and values.**\n",
            "\n",
            "So, while we may not know the \"one true answer,\" the journey of seeking meaning—living with intention and connection—is itself a powerful and meaningful part of being human.\n",
            "\n",
            "Would you like to explore a particular perspective (e.g., philosophy, religion, science) in more depth?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lmstudio as lms\n",
        "\n",
        "# Connect to the LM Studio server\n",
        "# Assuming the server is running on the default port 1234\n",
        "# If you configured a different port, update this line\n",
        "model = lms.llm(\"qwen/qwen3-4b-2507\")\n",
        "\n",
        "# Test the model\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "qztT7Yn4C6nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install lmstudio\n",
        "\n",
        "\n",
        "\n",
        "!lms get qwen/qwen3-4b-2507\n",
        "\n",
        "\n",
        "import lmstudio as lms\n",
        "\n",
        "# Connect to the LM Studio server\n",
        "# Assuming the server is running on the default port 1234\n",
        "# If you configured a different port, update this line\n",
        "model = lms.llm(\"qwen/qwen3-4b-2507\")\n",
        "\n",
        "# Test the model\n",
        "result = model.respond(\"What is the meaning of life?\")\n",
        "\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The question \"What is the meaning of life?\" is one of the most profound and enduring questions in human history. There is no single, universally accepted answer—because meaning is deeply personal and shaped by culture, religion, philosophy, science, and individual experience.\n",
        "\n",
        "Here are several perspectives on the meaning of life:\n",
        "\n",
        "1. **Philosophical Perspectives**\n",
        "   - **Existentialism** (e.g., Sartre, Camus): Life has no inherent meaning; it is up to each individual to create their own purpose through choices and actions.\n",
        "   - **Absurdism** (e.g., Camus): The conflict between the human search for meaning and the universe's apparent silence or randomness is absurd—but we can still find value through living authentically despite that absurdity.\n",
        "   - **Humanism**: Meaning comes from human values—love, creativity, knowledge, and contributing to society.\n",
        "\n",
        "2. **Religious and Spiritual Views**\n",
        "   - **Christianity, Islam, Judaism**: Life has meaning because it is a gift from a divine being, and the purpose is to live according to God’s will, love others, and prepare for an afterlife.\n",
        "   - **Buddhism**: The purpose of life is to attain enlightenment and end suffering through wisdom, compassion, and ethical living.\n",
        "   - **Hinduism**: Life is part of a cycle (samsara), and the ultimate goal is to achieve moksha (liberation) through dharma, karma, and devotion.\n",
        "\n",
        "3. **Scientific Perspective**\n",
        "   - From a biological standpoint, life's purpose may be to survive, reproduce, and pass on genes.\n",
        "   - From a cosmic view, life may be a natural byproduct of the universe's complexity and evolution—meaning is not something \"out there\" but something we construct through experience.\n",
        "\n",
        "4. **Personal Meaning**\n",
        "   Many people find meaning in relationships, achievements, service to others, creativity, or personal growth. As Viktor Frankl (a Holocaust survivor and psychiatrist) wrote in *Man’s Search for Meaning*, even in suffering, people find purpose through what they value and what they do—such as love, duty, or responsibility.\n",
        "\n",
        "💡 In short:\n",
        "**The meaning of life is not something discovered in a single moment or a textbook answer. It is something you build through your experiences, relationships, choices, and values.**\n",
        "\n",
        "So, while we may not know the \"one true answer,\" the journey of seeking meaning—living with intention and connection—is itself a powerful and meaningful part of being human.\n",
        "\n",
        "Would you like to explore a particular perspective (e.g., philosophy, religion, science) in more depth?"
      ],
      "metadata": {
        "id": "olMzfaAmDugT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}